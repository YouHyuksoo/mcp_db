"""
Oracle Database MCP ì„œë²„ ë©”ì¸
18ê°œ Tools ì œê³µ
- SQL ìƒì„±/ì‹¤í–‰ Tools (9ê°œ)
- ë©”íƒ€ë°ì´í„° ì¡°íšŒ Tools (6ê°œ)
- Vector DB ê¸°ë°˜ ê²€ìƒ‰ Tools (2ê°œ) â˜… ì»¬ëŸ¼ ê²€ìƒ‰ ì¶”ê°€
- ìœ í‹¸ë¦¬í‹° Tools (1ê°œ)
"""

import os
import sys
import logging
from pathlib import Path
from dotenv import load_dotenv

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ sys.pathì— ì¶”ê°€
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ì˜ .env íŒŒì¼ ë¡œë“œ
project_root = current_dir.parent
env_path = project_root / ".env"
load_dotenv(dotenv_path=env_path)

# MCP imports
from mcp.server import Server
from mcp.server.stdio import stdio_server

# ë¡œì»¬ ëª¨ë“ˆ imports
from oracle_connector import OracleConnector
from credentials_manager import CredentialsManager
from metadata_manager import MetadataManager
from sql_executor import SQLExecutor
from vector_db_client import get_vector_db
from feedback_manager import FeedbackManager

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# MCP ì„œë²„ ìƒì„±
server = Server("oracle-nlsql-mcp")

# ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ ì„¤ì • (í”„ë¡œì íŠ¸ ë£¨íŠ¸/data/)
data_dir = project_root / "data"
credentials_dir = data_dir / "credentials"
common_metadata_dir = data_dir / "common_metadata"
metadata_dir = data_dir / "metadata"
vector_db_dir = data_dir / "vector_db"

# ì „ì—­ ê°ì²´ë“¤
credentials_manager = CredentialsManager(credentials_dir=str(credentials_dir))
metadata_manager = MetadataManager(
    metadata_dir=str(metadata_dir)
)

# Vector DB í´ë¼ì´ì–¸íŠ¸ (í”¼ë“œë°± ì‹œìŠ¤í…œì— ì‚¬ìš©)
vector_db_client = get_vector_db()

# í”¼ë“œë°± ë§¤ë‹ˆì € ì´ˆê¸°í™”
feedback_manager = FeedbackManager(vector_db_client)

# DB ì»¤ë„¥í„° ìºì‹œ
db_connectors = {}


def get_connector(database_sid: str) -> OracleConnector:
    """DB ì»¤ë„¥í„° ê°€ì ¸ì˜¤ê¸° (ìºì‹±)"""
    if database_sid not in db_connectors:
        credentials = credentials_manager.load_credentials(database_sid)

        connector = OracleConnector(
            host=credentials['host'],
            port=credentials['port'],
            service_name=credentials['service_name'],
            user=credentials['user'],
            password=credentials['password']
        )

        connector.connect()
        db_connectors[database_sid] = connector

    return db_connectors[database_sid]


# ============================================
# Tools ëª©ë¡ ë“±ë¡
# ============================================
@server.list_tools()
async def list_tools() -> list:
    """ì‚¬ìš© ê°€ëŠ¥í•œ Tool ëª©ë¡ ë°˜í™˜"""
    import mcp.types as types

    return [
        types.Tool(
            name="register_database_credentials",
            description="DB ì ‘ì† ì •ë³´ë¥¼ ì•”í˜¸í™”í•˜ì—¬ ì €ì¥",
            inputSchema={
                "type": "object",
                "properties": {
                    "database_sid": {"type": "string", "description": "Database SID"},
                    "host": {"type": "string", "description": "í˜¸ìŠ¤íŠ¸ ì£¼ì†Œ"},
                    "port": {"type": "integer", "description": "í¬íŠ¸ ë²ˆí˜¸"},
                    "service_name": {"type": "string", "description": "ì„œë¹„ìŠ¤ ì´ë¦„"},
                    "user": {"type": "string", "description": "ì‚¬ìš©ì ì´ë¦„"},
                    "password": {"type": "string", "description": "ë¹„ë°€ë²ˆí˜¸"}
                },
                "required": ["database_sid", "host", "port", "service_name", "user", "password"]
            }
        ),
        types.Tool(
            name="list_available_databases",
            description="ì´ë¯¸ ë“±ë¡ëœ ë°ì´í„°ë² ì´ìŠ¤ ëª©ë¡ ì¡°íšŒ",
            inputSchema={
                "type": "object",
                "properties": {
                    "keyword": {"type": "string", "description": "ê²€ìƒ‰ í‚¤ì›Œë“œ (ì„ íƒ, DB SIDì—ì„œ ê²€ìƒ‰)"}
                }
            }
        ),
        types.Tool(
            name="connect_database",
            description="ë“±ë¡ëœ DBì— ì—°ê²° ë° ì ‘ì†ì •ë³´ ì €ì¥",
            inputSchema={
                "type": "object",
                "properties": {
                    "database_sid": {"type": "string", "description": "Database SID"},
                    "user": {"type": "string", "description": "ì‚¬ìš©ì ì´ë¦„"},
                    "password": {"type": "string", "description": "ë¹„ë°€ë²ˆí˜¸"}
                },
                "required": ["database_sid", "user", "password"]
            }
        ),
        types.Tool(
            name="show_databases",
            description="ë“±ë¡ëœ DB ëª©ë¡ ì¡°íšŒ",
            inputSchema={"type": "object", "properties": {}}
        ),
        types.Tool(
            name="show_connection_status",
            description="ì ‘ì† ê°€ëŠ¥í•œ DB ëª©ë¡ê³¼ ì—°ê²° ì •ë³´ ìƒíƒœ ë³´ê³ ",
            inputSchema={"type": "object", "properties": {}}
        ),
        types.Tool(
            name="show_schemas",
            description="íŠ¹ì • DBì˜ ìŠ¤í‚¤ë§ˆ ëª©ë¡ ì¡°íšŒ",
            inputSchema={
                "type": "object",
                "properties": {
                    "database_sid": {"type": "string", "description": "Database SID"}
                },
                "required": ["database_sid"]
            }
        ),
        types.Tool(
            name="show_tables",
            description="íŠ¹ì • ìŠ¤í‚¤ë§ˆì˜ í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ",
            inputSchema={
                "type": "object",
                "properties": {
                    "database_sid": {"type": "string", "description": "Database SID"},
                    "schema_name": {"type": "string", "description": "ìŠ¤í‚¤ë§ˆ ì´ë¦„"},
                    "table_filter": {"type": "string", "description": "í…Œì´ë¸” ì´ë¦„ í•„í„° (LIKE íŒ¨í„´, ì˜ˆ: 'ISYS_%', '%_MASTER'). ì„ íƒì‚¬í•­."}
                },
                "required": ["database_sid", "schema_name"]
            }
        ),
        types.Tool(
            name="describe_table",
            description="í…Œì´ë¸” êµ¬ì¡° ìƒì„¸ ì¡°íšŒ",
            inputSchema={
                "type": "object",
                "properties": {
                    "database_sid": {"type": "string", "description": "Database SID"},
                    "schema_name": {"type": "string", "description": "ìŠ¤í‚¤ë§ˆ ì´ë¦„"},
                    "table_name": {"type": "string", "description": "í…Œì´ë¸” ì´ë¦„"}
                },
                "required": ["database_sid", "schema_name", "table_name"]
            }
        ),
        types.Tool(
            name="show_procedures",
            description="íŠ¹ì • ìŠ¤í‚¤ë§ˆì˜ í”„ë¡œì‹œì € ëª©ë¡ ì¡°íšŒ",
            inputSchema={
                "type": "object",
                "properties": {
                    "database_sid": {"type": "string", "description": "Database SID"},
                    "schema_name": {"type": "string", "description": "ìŠ¤í‚¤ë§ˆ ì´ë¦„"}
                },
                "required": ["database_sid", "schema_name"]
            }
        ),
        types.Tool(
            name="show_procedure_source",
            description="í”„ë¡œì‹œì € ì†ŒìŠ¤ ì½”ë“œ ì¡°íšŒ",
            inputSchema={
                "type": "object",
                "properties": {
                    "database_sid": {"type": "string", "description": "Database SID"},
                    "schema_name": {"type": "string", "description": "ìŠ¤í‚¤ë§ˆ ì´ë¦„"},
                    "procedure_name": {"type": "string", "description": "í”„ë¡œì‹œì € ì´ë¦„"}
                },
                "required": ["database_sid", "schema_name", "procedure_name"]
            }
        ),
        types.Tool(
            name="execute_sql",
            description="SQL ì¿¼ë¦¬ ì‹¤í–‰",
            inputSchema={
                "type": "object",
                "properties": {
                    "database_sid": {"type": "string", "description": "Database SID"},
                    "sql": {"type": "string", "description": "ì‹¤í–‰í•  SQL"},
                    "max_rows": {"type": "integer", "description": "ìµœëŒ€ ì¡°íšŒ í–‰ ìˆ˜"}
                },
                "required": ["database_sid", "sql"]
            }
        ),
        types.Tool(
            name="get_table_summaries_for_query",
            description="Stage 1: ìì—°ì–´ ì§ˆì˜ë¥¼ ìœ„í•œ í…Œì´ë¸” ìš”ì•½ ì¡°íšŒ (Vector DB ê¸°ë°˜ ì˜ë¯¸ ê²€ìƒ‰)",
            inputSchema={
                "type": "object",
                "properties": {
                    "database_sid": {"type": "string", "description": "Database SID"},
                    "schema_name": {"type": "string", "description": "ìŠ¤í‚¤ë§ˆ ì´ë¦„"},
                    "natural_query": {"type": "string", "description": "ìì—°ì–´ ì§ˆë¬¸"}
                },
                "required": ["database_sid", "schema_name"]
            }
        ),
        types.Tool(
            name="check_vectordb_status",
            description="Vector DB ìƒíƒœ í™•ì¸ (í•™ìŠµ ì—¬ë¶€, í…Œì´ë¸” ìˆ˜ ë“±)",
            inputSchema={"type": "object", "properties": {}}
        ),
        types.Tool(
            name="get_detailed_metadata_for_sql",
            description="Stage 2: SQL ìƒì„±ì„ ìœ„í•œ ìƒì„¸ ë©”íƒ€ë°ì´í„° ì¡°íšŒ",
            inputSchema={
                "type": "object",
                "properties": {
                    "database_sid": {"type": "string", "description": "Database SID"},
                    "schema_name": {"type": "string", "description": "ìŠ¤í‚¤ë§ˆ ì´ë¦„"},
                    "table_names": {"type": "array", "description": "í…Œì´ë¸” ì´ë¦„ ëª©ë¡"}
                },
                "required": ["database_sid", "schema_name", "table_names"]
            }
        ),
        types.Tool(
            name="get_table_metadata",
            description="íŠ¹ì • í…Œì´ë¸”ì˜ í†µí•© ë©”íƒ€ë°ì´í„° ì¡°íšŒ",
            inputSchema={
                "type": "object",
                "properties": {
                    "database_sid": {"type": "string", "description": "Database SID"},
                    "schema_name": {"type": "string", "description": "ìŠ¤í‚¤ë§ˆ ì´ë¦„"},
                    "table_name": {"type": "string", "description": "í…Œì´ë¸” ì´ë¦„"}
                },
                "required": ["database_sid", "schema_name", "table_name"]
            }
        ),
        types.Tool(
            name="view_sql_rules",
            description="í˜„ì¬ ì„¤ì •ëœ SQL ì‘ì„± ê·œì¹™ ì¡°íšŒ",
            inputSchema={"type": "object", "properties": {}}
        ),
        types.Tool(
            name="update_sql_rules",
            description="SQL ì‘ì„± ê·œì¹™ ì—…ë°ì´íŠ¸ (Markdown í˜•ì‹)",
            inputSchema={
                "type": "object",
                "properties": {
                    "rules_content": {"type": "string", "description": "ìƒˆë¡œìš´ SQL ê·œì¹™ ë‚´ìš© (Markdown í˜•ì‹)"}
                },
                "required": ["rules_content"]
            }
        ),
        types.Tool(
            name="search_columns",
            description="â˜… ìì—°ì–´ë¡œ ì»¬ëŸ¼ ê²€ìƒ‰ (ì˜ë¯¸ ê¸°ë°˜, Vector DB ì‚¬ìš©)",
            inputSchema={
                "type": "object",
                "properties": {
                    "database_sid": {"type": "string", "description": "Database SID"},
                    "schema_name": {"type": "string", "description": "ìŠ¤í‚¤ë§ˆ ì´ë¦„"},
                    "query": {"type": "string", "description": "ìì—°ì–´ ê²€ìƒ‰ì–´ (ì˜ˆ: 'ë¼ì¸', 'ì¼ì', 'ìˆ˜ëŸ‰', 'ëª¨ë¸ëª…')"},
                    "table_name": {"type": "string", "description": "íŠ¹ì • í…Œì´ë¸”ë¡œ ì œí•œ (ì„ íƒì‚¬í•­)"},
                    "n_results": {"type": "integer", "description": "ë°˜í™˜í•  ì»¬ëŸ¼ ìˆ˜ (ê¸°ë³¸ê°’: 10)"}
                },
                "required": ["database_sid", "schema_name", "query"]
            }
        ),
        types.Tool(
            name="generate_and_review_sql",
            description="â˜… SQL ìƒì„± í›„ ë¯¸ë¦¬ë³´ê¸° (ê²€í†  ê¸°ëŠ¥ í¬í•¨) - ì˜µì…˜ A",
            inputSchema={
                "type": "object",
                "properties": {
                    "database_sid": {"type": "string", "description": "Database SID"},
                    "schema_name": {"type": "string", "description": "ìŠ¤í‚¤ë§ˆ ì´ë¦„"},
                    "natural_query": {"type": "string", "description": "ìì—°ì–´ ì§ˆë¬¸ (ì˜ˆ: 'Run Cardì˜ ë‹¹ì¼ ìƒì‚° ê³„íšìˆ˜ëŸ‰ì„ ëª¨ë¸ë³„ë¡œ í•©ê³„í•´ì„œ ë³´ì—¬ì¤˜')"},
                    "created_by": {"type": "string", "description": "ì‚¬ìš©ì ì •ë³´ (ì„ íƒ)"}
                },
                "required": ["database_sid", "schema_name", "natural_query"]
            }
        ),
        types.Tool(
            name="submit_sql_feedback",
            description="â˜… ì‚¬ìš©ì í”¼ë“œë°± ì €ì¥ ë° ê°€ì¤‘ì¹˜ ê³„ì‚° (í”¼ë“œë°± ì²˜ë¦¬)",
            inputSchema={
                "type": "object",
                "properties": {
                    "feedback_id": {"type": "string", "description": "í”¼ë“œë°± ID"},
                    "action": {"type": "string", "description": "approve (ìŠ¹ì¸), modify (ìˆ˜ì •), reject (ê±°ë¶€)", "enum": ["approve", "modify", "reject"]},
                    "suggestions": {"type": "string", "description": "ì‚¬ìš©ì ì œì•ˆ/ì¡°ì–¸ (ìˆ˜ì • ë˜ëŠ” ê±°ë¶€ ì‹œ)"},
                    "user_confidence": {"type": "number", "description": "ì‚¬ìš©ì ì‹ ë¢°ë„ (0.0~1.0)"}
                },
                "required": ["feedback_id", "action"]
            }
        ),
        types.Tool(
            name="regenerate_sql_with_feedback",
            description="â˜… ì‚¬ìš©ì í”¼ë“œë°±ì„ ë°˜ì˜í•˜ì—¬ SQL ì¬ìƒì„±",
            inputSchema={
                "type": "object",
                "properties": {
                    "feedback_id": {"type": "string", "description": "í”¼ë“œë°± ID"},
                    "feedback_text": {"type": "string", "description": "ì‚¬ìš©ì í”¼ë“œë°± (ìˆ˜ì • ìš”ì²­ ì‚¬í•­)"}
                },
                "required": ["feedback_id", "feedback_text"]
            }
        ),
        types.Tool(
            name="execute_sql_direct",
            description="SQL ì§ì ‘ ì‹¤í–‰ (í”¼ë“œë°± ì—†ì´ ë°”ë¡œ ì‹¤í–‰) - ì˜µì…˜ B",
            inputSchema={
                "type": "object",
                "properties": {
                    "database_sid": {"type": "string", "description": "Database SID"},
                    "sql": {"type": "string", "description": "ì‹¤í–‰í•  SQL"},
                    "max_rows": {"type": "integer", "description": "ìµœëŒ€ ì¡°íšŒ í–‰ ìˆ˜"}
                },
                "required": ["database_sid", "sql"]
            }
        ),
    ]


# ============================================
# Tool ì‹¤í–‰ ë¼ìš°í„°
# ============================================
@server.call_tool()
async def handle_call_tool(name: str, arguments: dict):
    """ë‹¨ì¼ Tool ë¼ìš°í„° - ëª¨ë“  Tool í˜¸ì¶œì„ ì ì ˆí•œ í•¨ìˆ˜ë¡œ ë¼ìš°íŒ…"""
    import mcp.types as types

    try:
        # Tool ì´ë¦„ì— ë”°ë¼ ì ì ˆí•œ í•¨ìˆ˜ í˜¸ì¶œ
        if name == "register_database_credentials":
            result = await register_database_credentials(**arguments)
        elif name == "list_available_databases":
            result = await list_available_databases(**arguments)
        elif name == "connect_database":
            result = await connect_database(**arguments)
        elif name == "show_databases":
            result = await show_databases(**arguments)
        elif name == "show_connection_status":
            result = await show_connection_status(**arguments)
        elif name == "show_schemas":
            result = await show_schemas(**arguments)
        elif name == "show_tables":
            result = await show_tables(**arguments)
        elif name == "describe_table":
            result = await describe_table(**arguments)
        elif name == "show_procedures":
            result = await show_procedures(**arguments)
        elif name == "show_procedure_source":
            result = await show_procedure_source(**arguments)
        elif name == "execute_sql":
            result = await execute_sql(**arguments)
        elif name == "get_table_summaries_for_query":
            result = await get_table_summaries_for_query(**arguments)
        elif name == "check_vectordb_status":
            result = await check_vectordb_status(**arguments)
        elif name == "get_detailed_metadata_for_sql":
            result = await get_detailed_metadata_for_sql(**arguments)
        elif name == "get_table_metadata":
            result = await get_table_metadata(**arguments)
        elif name == "view_sql_rules":
            result = await view_sql_rules(**arguments)
        elif name == "update_sql_rules":
            result = await update_sql_rules(**arguments)
        elif name == "search_columns":
            result = await search_columns(**arguments)
        elif name == "generate_and_review_sql":
            result = await generate_and_review_sql(**arguments)
        elif name == "submit_sql_feedback":
            result = await submit_sql_feedback(**arguments)
        elif name == "regenerate_sql_with_feedback":
            result = await regenerate_sql_with_feedback(**arguments)
        elif name == "execute_sql_direct":
            result = await execute_sql_direct(**arguments)
        else:
            return types.CallToolResult(
                content=[types.TextContent(type="text", text=f"âŒ Unknown tool: {name}")],
                isError=True
            )

        # ê²°ê³¼ê°€ ì´ë¯¸ list[dict] í˜•íƒœë¼ë©´ ë³€í™˜
        if isinstance(result, list):
            content = [types.TextContent(type=item.get("type", "text"), text=item.get("text", "")) for item in result]
            return types.CallToolResult(content=content)
        else:
            return types.CallToolResult(
                content=[types.TextContent(type="text", text=str(result))]
            )

    except Exception as e:
        import traceback
        return types.CallToolResult(
            content=[types.TextContent(type="text", text=f"âŒ ì—ëŸ¬: {str(e)}\n\n{traceback.format_exc()}")],
            isError=True
        )


# ============================================
# Tool 1: DB ì ‘ì† ì •ë³´ ë“±ë¡
# ============================================
async def register_database_credentials(
    database_sid: str,
    host: str,
    port: int,
    service_name: str,
    user: str,
    password: str
) -> list[dict]:
    """DB ì ‘ì† ì •ë³´ ì•”í˜¸í™”í•˜ì—¬ ì €ì¥"""
    try:
        credentials = {
            'host': host,
            'port': port,
            'service_name': service_name,
            'user': user,
            'password': password
        }

        success = credentials_manager.save_credentials(database_sid, credentials)

        if success:
            return [{
                "type": "text",
                "text": f"âœ… DB ì ‘ì† ì •ë³´ ì €ì¥ ì™„ë£Œ: {database_sid}"
            }]
        else:
            return [{
                "type": "text",
                "text": f"âŒ DB ì ‘ì† ì •ë³´ ì €ì¥ ì‹¤íŒ¨: {database_sid}"
            }]

    except Exception as e:
        import traceback
        logger.error(f"ì—ëŸ¬ ë°œìƒ: {e}\n{traceback.format_exc()}")
        return [{
            "type": "text",
            "text": f"âŒ ì—ëŸ¬: {str(e)}\n\n{traceback.format_exc()}"
        }]


# ============================================
# Tool 2: ì‚¬ìš© ê°€ëŠ¥í•œ DB ëª©ë¡ ì¡°íšŒ
# ============================================

async def list_available_databases(
    keyword: str = ""
) -> list[dict]:
    """
    ì´ë¯¸ ë“±ë¡ëœ ë°ì´í„°ë² ì´ìŠ¤ ëª©ë¡ ì¡°íšŒ

    Args:
        keyword: ê²€ìƒ‰ í‚¤ì›Œë“œ (ì„ íƒ, DB SIDì—ì„œ ê²€ìƒ‰)
    """
    try:
        # ë“±ë¡ëœ credentials ëª©ë¡ ì¡°íšŒ
        registered_dbs = credentials_manager.list_databases()

        if not registered_dbs:
            return [{
                "type": "text",
                "text": "âŒ ë“±ë¡ëœ ë°ì´í„°ë² ì´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.\n\n"
                       "ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ì‹œë„í•˜ì„¸ìš”:\n"
                       "1. `register_database_credentials` Toolë¡œ ìˆ˜ë™ ë“±ë¡\n"
                       "2. Backend Web UIì—ì„œ tnsnames.ora íŒŒì¼ì„ íŒŒì‹±í•˜ì—¬ ë“±ë¡"
            }]

        # í‚¤ì›Œë“œ í•„í„°ë§
        if keyword:
            keyword_lower = keyword.lower()
            filtered = [
                db_sid for db_sid in registered_dbs
                if keyword_lower in db_sid.lower()
            ]
        else:
            filtered = registered_dbs

        result_text = f"ğŸ“Š ë“±ë¡ëœ ë°ì´í„°ë² ì´ìŠ¤ ëª©ë¡\n\n"

        if keyword:
            result_text += f"**ê²€ìƒ‰ í‚¤ì›Œë“œ**: {keyword}\n"
            result_text += f"**ê²€ìƒ‰ ê²°ê³¼**: {len(filtered)}ê°œ\n\n"
        else:
            result_text += f"**ì „ì²´ DB ìˆ˜**: {len(filtered)}ê°œ\n\n"

        # DB ëª©ë¡ (ìµœëŒ€ 20ê°œë§Œ í‘œì‹œ)
        count = 0
        for db_sid in sorted(filtered):
            if count >= 20:
                result_text += f"\n... ì™¸ {len(filtered) - 20}ê°œ ë” ìˆìŒ\n"
                break

            try:
                # ë“±ë¡ëœ credentials ì •ë³´ ì¡°íšŒ (ë¹„ë°€ë²ˆí˜¸ ì œì™¸)
                creds = credentials_manager.load_credentials(db_sid)
                result_text += f"### {db_sid}\n"
                result_text += f"  - **í˜¸ìŠ¤íŠ¸**: {creds['host']}:{creds['port']}\n"
                result_text += f"  - **ì„œë¹„ìŠ¤ëª…**: {creds['service_name']}\n"
                result_text += f"  - **ì‚¬ìš©ì**: {creds.get('user', 'N/A')}\n\n"
            except Exception as e:
                result_text += f"### {db_sid}\n"
                result_text += f"  - **ìƒíƒœ**: ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨\n\n"
            count += 1

        result_text += "\n**ë‹¤ìŒ ë‹¨ê³„**: `connect_database` Toolë¡œ ì—°ê²°í•˜ê±°ë‚˜ `register_database_credentials` Toolë¡œ ìƒˆë¡œ ë“±ë¡í•˜ì„¸ìš”."

        return [{
            "type": "text",
            "text": result_text
        }]

    except Exception as e:
        import traceback
        logger.error(f"DB ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}\n{traceback.format_exc()}")
        return [{
            "type": "text",
            "text": f"âŒ DB ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}\n\n{traceback.format_exc()}"
        }]


# ============================================
# Tool 4: ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë° ì €ì¥
# ============================================

async def connect_database(
    database_sid: str,
    user: str,
    password: str
) -> list[dict]:
    """
    DBì— ì—°ê²° ë° ì ‘ì†ì •ë³´ ì €ì¥ (ì´ë¯¸ ë“±ë¡ëœ credentials ì‚¬ìš©)

    Args:
        database_sid: DB SID (ì˜ˆ: SOLUM, JSTECH)
        user: Oracle ì‚¬ìš©ìëª… (ì˜ˆ: scott, system)
        password: Oracle ë¹„ë°€ë²ˆí˜¸
    """
    try:
        # ë“±ë¡ëœ credentials í™•ì¸
        try:
            existing_credentials = credentials_manager.load_credentials(database_sid)
            db_info = {
                'host': existing_credentials['host'],
                'port': existing_credentials['port'],
                'service_name': existing_credentials['service_name']
            }
            logger.info(f"ì´ë¯¸ ë“±ë¡ëœ credentials ì‚¬ìš©: {database_sid}")
        except Exception as e:
            # ë“±ë¡ëœ credentials ì—†ìŒ
            return [{
                "type": "text",
                "text": f"âŒ DBë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {database_sid}\n\n"
                       f"ë¨¼ì € `register_database_credentials` Toolë¡œ DB ì ‘ì† ì •ë³´ë¥¼ ë“±ë¡í•˜ì„¸ìš”.\n"
                       f"ë˜ëŠ” Backend Web UIì—ì„œ tnsnames.ora íŒŒì¼ì„ íŒŒì‹±í•˜ì—¬ ë“±ë¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            }]

        # ì—°ê²° í…ŒìŠ¤íŠ¸
        connector = OracleConnector(
            host=db_info['host'],
            port=db_info['port'],
            service_name=db_info['service_name'],
            user=user,
            password=password
        )

        if not connector.connect():
            return [{
                "type": "text",
                "text": f"âŒ DB ì—°ê²° ì‹¤íŒ¨: {database_sid}\n\nì‚¬ìš©ìëª…ê³¼ ë¹„ë°€ë²ˆí˜¸ë¥¼ í™•ì¸í•˜ì„¸ìš”."
            }]

        # ì—°ê²° ì„±ê³µ ì‹œ credentials ì €ì¥ (ë¹„ë°€ë²ˆí˜¸ ì—…ë°ì´íŠ¸ í¬í•¨)
        credentials = {
            'host': db_info['host'],
            'port': db_info['port'],
            'service_name': db_info['service_name'],
            'user': user,
            'password': password
        }

        success = credentials_manager.save_credentials(database_sid, credentials)

        if success:
            result_text = f"âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ ë° ì €ì¥ ì™„ë£Œ\n\n"
            result_text += f"**Database SID**: {database_sid}\n"
            result_text += f"**í˜¸ìŠ¤íŠ¸**: {db_info['host']}:{db_info['port']}\n"
            result_text += f"**ì„œë¹„ìŠ¤ëª…**: {db_info['service_name']}\n"
            result_text += f"**ì‚¬ìš©ì**: {user}\n"
            result_text += f"\nâœ… ì ‘ì† ì •ë³´ê°€ ì•”í˜¸í™”ë˜ì–´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
            result_text += f"ì´ì œ ì´ DBë¥¼ ìë™ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n"
            result_text += "**ë‹¤ìŒ ë‹¨ê³„**: \n"
            result_text += f"- `show_schemas` Toolë¡œ ìŠ¤í‚¤ë§ˆ ëª©ë¡ í™•ì¸\n"
            result_text += f"- Backend Web UIì—ì„œ CSV ì—…ë¡œë“œ ë˜ëŠ” ë©”íƒ€ë°ì´í„° ê´€ë¦¬"

            # ìºì‹œì—ì„œ ì»¤ë„¥í„° ì œê±° (ìƒˆë¡œ ì—°ê²°í•˜ë„ë¡)
            if database_sid in db_connectors:
                del db_connectors[database_sid]

            return [{
                "type": "text",
                "text": result_text
            }]
        else:
            return [{
                "type": "text",
                "text": f"âŒ ì ‘ì† ì •ë³´ ì €ì¥ ì‹¤íŒ¨: {database_sid}"
            }]

    except Exception as e:
        import traceback
        logger.error(f"DB ì—°ê²° ì‹¤íŒ¨: {e}\n{traceback.format_exc()}")
        return [{
            "type": "text",
            "text": f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {str(e)}\n\nì‚¬ìš©ìëª…ê³¼ ë¹„ë°€ë²ˆí˜¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.\n\n{traceback.format_exc()}"
        }]


# ============================================
# Tool 3: ë°ì´í„°ë² ì´ìŠ¤ ëª©ë¡
# ============================================

async def show_databases() -> list[dict]:
    """ë“±ë¡ëœ ëª¨ë“  ë°ì´í„°ë² ì´ìŠ¤ ëª©ë¡"""
    try:
        databases = credentials_manager.list_databases()

        if not databases:
            return [{
                "type": "text",
                "text": "ë“±ë¡ëœ ë°ì´í„°ë² ì´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤."
            }]

        result_text = f"ğŸ“‚ ë“±ë¡ëœ ë°ì´í„°ë² ì´ìŠ¤ ({len(databases)}ê°œ)\n\n"
        for db_sid in databases:
            result_text += f"- {db_sid}\n"

        return [{"type": "text", "text": result_text}]

    except Exception as e:
        import traceback
        logger.error(f"ì—ëŸ¬ ë°œìƒ: {e}\n{traceback.format_exc()}")
        return [{
            "type": "text",
            "text": f"âŒ ì—ëŸ¬: {str(e)}\n\n{traceback.format_exc()}"
        }]


# ============================================
# Tool: ì—°ê²° ìƒíƒœ ë³´ê³ 
# ============================================

async def show_connection_status() -> list[dict]:
    """ì ‘ì† ê°€ëŠ¥í•œ DB ëª©ë¡ê³¼ ì—°ê²° ì •ë³´, ë©”íƒ€ë°ì´í„° ìƒíƒœ ë³´ê³ """
    try:
        import json
        from pathlib import Path

        databases = credentials_manager.list_databases()

        if not databases:
            return [{
                "type": "text",
                "text": "ë“±ë¡ëœ ë°ì´í„°ë² ì´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤."
            }]

        result_text = f"ğŸ“Š **ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ìƒíƒœ ë³´ê³ **\n\n"
        result_text += f"ë“±ë¡ëœ ë°ì´í„°ë² ì´ìŠ¤: **{len(databases)}ê°œ**\n\n"
        result_text += "=" * 60 + "\n\n"

        for db_sid in databases:
            result_text += f"## ğŸ—„ï¸ {db_sid}\n\n"

            try:
                # 1. ì—°ê²° ì •ë³´ ë¡œë“œ
                credentials = credentials_manager.load_credentials(db_sid)
                result_text += f"### ğŸ“¡ ì—°ê²° ì •ë³´\n"
                result_text += f"- **í˜¸ìŠ¤íŠ¸**: {credentials['host']}:{credentials['port']}\n"
                result_text += f"- **ì„œë¹„ìŠ¤ëª…**: {credentials['service_name']}\n"
                result_text += f"- **ì‚¬ìš©ì**: {credentials['user']}\n"
                result_text += f"- **ë¹„ë°€ë²ˆí˜¸**: {'*' * len(credentials['password'])}\n\n"

                # 2. ì—°ê²° í…ŒìŠ¤íŠ¸
                try:
                    connector = OracleConnector(
                        host=credentials['host'],
                        port=credentials['port'],
                        service_name=credentials['service_name'],
                        user=credentials['user'],
                        password=credentials['password']
                    )
                    if connector.connect():
                        result_text += f"- **ì—°ê²° ìƒíƒœ**: âœ… ì—°ê²° ê°€ëŠ¥\n\n"

                        # 3. ìŠ¤í‚¤ë§ˆ ëª©ë¡ ì¡°íšŒ
                        try:
                            schemas = connector.list_schemas()
                            result_text += f"### ğŸ“‚ ìŠ¤í‚¤ë§ˆ ëª©ë¡\n"
                            result_text += f"- **ìŠ¤í‚¤ë§ˆ ìˆ˜**: {len(schemas)}ê°œ\n"
                            result_text += f"- **ëª©ë¡**: {', '.join(schemas[:5])}"
                            if len(schemas) > 5:
                                result_text += f" ì™¸ {len(schemas) - 5}ê°œ"
                            result_text += "\n\n"
                        except Exception as e:
                            result_text += f"### ğŸ“‚ ìŠ¤í‚¤ë§ˆ ëª©ë¡\n"
                            result_text += f"- âš ï¸ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}\n\n"

                        connector.disconnect()
                    else:
                        result_text += f"- **ì—°ê²° ìƒíƒœ**: âŒ ì—°ê²° ì‹¤íŒ¨\n\n"
                except Exception as e:
                    result_text += f"- **ì—°ê²° ìƒíƒœ**: âŒ ì—°ê²° ì‹¤íŒ¨ ({str(e)})\n\n"

                # 4. Vector DB ë©”íƒ€ë°ì´í„° ìƒíƒœ
                result_text += f"### ğŸ—‚ï¸ í†µí•© ë©”íƒ€ë°ì´í„° ìƒíƒœ\n"
                metadata_dir = Path("./metadata") / db_sid
                if metadata_dir.exists():
                    schema_dirs = [d for d in metadata_dir.iterdir() if d.is_dir()]
                    total_tables = 0
                    schema_info = []

                    for schema_dir in schema_dirs:
                        table_dirs = [d for d in schema_dir.iterdir() if d.is_dir()]
                        table_count = len(table_dirs)
                        total_tables += table_count
                        if table_count > 0:
                            schema_info.append(f"{schema_dir.name} ({table_count}ê°œ)")

                    if total_tables > 0:
                        result_text += f"- **ìƒì„±ëœ ë©”íƒ€ë°ì´í„°**: âœ… {total_tables}ê°œ í…Œì´ë¸”\n"
                        result_text += f"- **ìŠ¤í‚¤ë§ˆë³„**:\n"
                        for info in schema_info[:5]:
                            result_text += f"  - {info}\n"
                        if len(schema_info) > 5:
                            result_text += f"  - ... ì™¸ {len(schema_info) - 5}ê°œ\n"
                    else:
                        result_text += f"- **ìƒì„±ëœ ë©”íƒ€ë°ì´í„°**: âš ï¸ ì—†ìŒ\n"
                else:
                    result_text += f"- **ìƒì„±ëœ ë©”íƒ€ë°ì´í„°**: âš ï¸ ì—†ìŒ\n"
                result_text += "\n"

                # 6. CSV íŒŒì¼ ìƒíƒœ
                result_text += f"### ğŸ“„ CSV íŒŒì¼ ìƒíƒœ\n"
                common_metadata_dir = Path("./common_metadata") / db_sid
                csv_files = []
                if common_metadata_dir.exists():
                    if (common_metadata_dir / "common_columns.json").exists():
                        csv_files.append("âœ… ê³µí†µ ì¹¼ëŸ¼ ë¡œë“œë¨")
                    else:
                        csv_files.append("âš ï¸ ê³µí†µ ì¹¼ëŸ¼ ë¯¸ë¡œë“œ")

                    if (common_metadata_dir / "code_definitions.json").exists():
                        csv_files.append("âœ… ì½”ë“œ ì •ì˜ ë¡œë“œë¨")
                    else:
                        csv_files.append("âš ï¸ ì½”ë“œ ì •ì˜ ë¯¸ë¡œë“œ")

                    # ìŠ¤í‚¤ë§ˆë³„ í…Œì´ë¸” ì •ë³´ í™•ì¸
                    schema_files = list(common_metadata_dir.glob("*/table_info.json"))
                    if schema_files:
                        csv_files.append(f"âœ… í…Œì´ë¸” ì •ë³´ ({len(schema_files)}ê°œ ìŠ¤í‚¤ë§ˆ)")
                    else:
                        csv_files.append("âš ï¸ í…Œì´ë¸” ì •ë³´ ë¯¸ë¡œë“œ")
                else:
                    csv_files.append("âš ï¸ ê³µí†µ ë©”íƒ€ë°ì´í„° ë””ë ‰í† ë¦¬ ì—†ìŒ")

                for file_status in csv_files:
                    result_text += f"- {file_status}\n"
                result_text += "\n"

            except Exception as e:
                result_text += f"âŒ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}\n\n"

            result_text += "=" * 60 + "\n\n"

        result_text += "\n**ğŸ“Œ ì°¸ê³ ì‚¬í•­**:\n"
        result_text += "- CSV ì—…ë¡œë“œ ë° ë©”íƒ€ë°ì´í„° ê´€ë¦¬: Backend Web UIì—ì„œ ìˆ˜í–‰\n"
        result_text += "- Vector DB ë©”íƒ€ë°ì´í„°: Backendë¥¼ í†µí•´ í•™ìŠµ í›„ MCPê°€ ë…ë¦½ì ìœ¼ë¡œ ì‚¬ìš©\n"

        return [{"type": "text", "text": result_text}]

    except Exception as e:
        logger.error(f"ì—°ê²° ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        import traceback
        return [{
            "type": "text",
            "text": f"âŒ ì—°ê²° ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}\n\n{traceback.format_exc()}"
        }]


# ============================================
# Tool 4: ìŠ¤í‚¤ë§ˆ ëª©ë¡
# ============================================

async def show_schemas(database_sid: str) -> list[dict]:
    """íŠ¹ì • DBì˜ ëª¨ë“  ìŠ¤í‚¤ë§ˆ ëª©ë¡"""
    try:
        connector = get_connector(database_sid)
        schemas = connector.list_schemas()

        result_text = f"ğŸ“‚ {database_sid}ì˜ ìŠ¤í‚¤ë§ˆ ëª©ë¡ ({len(schemas)}ê°œ)\n\n"
        for schema in schemas:
            result_text += f"- {schema}\n"

        return [{"type": "text", "text": result_text}]

    except Exception as e:
        import traceback
        logger.error(f"ì—ëŸ¬ ë°œìƒ: {e}\n{traceback.format_exc()}")
        return [{
            "type": "text",
            "text": f"âŒ ì—ëŸ¬: {str(e)}\n\n{traceback.format_exc()}"
        }]


# ============================================
# Tool 5: í…Œì´ë¸” ëª©ë¡
# ============================================

async def show_tables(database_sid: str, schema_name: str, table_filter: str = None) -> list[dict]:
    """
    íŠ¹ì • ìŠ¤í‚¤ë§ˆì˜ í…Œì´ë¸” ëª©ë¡

    Args:
        database_sid: Database SID
        schema_name: ìŠ¤í‚¤ë§ˆ ì´ë¦„
        table_filter: í…Œì´ë¸” ì´ë¦„ í•„í„° (LIKE íŒ¨í„´, ì˜ˆ: 'ISYS_%', '%_MASTER')
    """
    try:
        connector = get_connector(database_sid)
        tables = connector.list_tables(schema_name, table_filter)

        if table_filter:
            result_text = f"ğŸ“‹ {database_sid}.{schema_name}ì˜ í…Œì´ë¸” ëª©ë¡ (í•„í„°: {table_filter}) ({len(tables)}ê°œ)\n\n"
        else:
            result_text = f"ğŸ“‹ {database_sid}.{schema_name}ì˜ í…Œì´ë¸” ëª©ë¡ ({len(tables)}ê°œ)\n\n"

        for table in tables:
            result_text += f"- {table['TABLE_NAME']}"
            if table.get('NUM_ROWS'):
                result_text += f" ({table['NUM_ROWS']:,}ê°œ í–‰)"
            result_text += "\n"

        return [{"type": "text", "text": result_text}]

    except Exception as e:
        import traceback
        logger.error(f"ì—ëŸ¬ ë°œìƒ: {e}\n{traceback.format_exc()}")
        return [{
            "type": "text",
            "text": f"âŒ ì—ëŸ¬: {str(e)}\n\n{traceback.format_exc()}"
        }]


# ============================================
# Tool 6: í…Œì´ë¸” êµ¬ì¡° ìƒì„¸
# ============================================

async def describe_table(
    database_sid: str,
    schema_name: str,
    table_name: str
) -> list[dict]:
    """í…Œì´ë¸” êµ¬ì¡° ìƒì„¸ ì¡°íšŒ"""
    try:
        connector = get_connector(database_sid)

        # ì¹¼ëŸ¼ ì •ë³´
        columns = connector.extract_table_columns(schema_name, table_name)
        primary_keys = connector.extract_primary_keys(schema_name, table_name)
        foreign_keys = connector.extract_foreign_keys(schema_name, table_name)
        indexes = connector.extract_indexes(schema_name, table_name)
        comment = connector.get_table_comment(schema_name, table_name)

        result_text = f"ğŸ“Š í…Œì´ë¸” êµ¬ì¡°: {database_sid}.{schema_name}.{table_name}\n\n"

        if comment:
            result_text += f"ì„¤ëª…: {comment}\n\n"

        result_text += "## ì¹¼ëŸ¼\n\n"
        for col in columns:
            pk_mark = " [PK]" if col['COLUMN_NAME'] in primary_keys else ""
            nullable = "NULL" if col['NULLABLE'] == 'Y' else "NOT NULL"

            result_text += f"- {col['COLUMN_NAME']}{pk_mark}\n"
            result_text += f"  íƒ€ì…: {col['DATA_TYPE']}, {nullable}\n"
            if col.get('COMMENTS'):
                result_text += f"  ì„¤ëª…: {col['COMMENTS']}\n"
            result_text += "\n"

        if foreign_keys:
            result_text += "\n## Foreign Keys\n\n"
            for fk in foreign_keys:
                result_text += f"- {fk['COLUMN_NAME']} â†’ {fk['REF_TABLE']}.{fk['REF_COLUMN']}\n"

        if indexes:
            result_text += "\n## Indexes\n\n"
            for idx in indexes:
                result_text += f"- {idx['INDEX_NAME']} ({idx['UNIQUENESS']}): {idx['COLUMNS']}\n"

        return [{"type": "text", "text": result_text}]

    except Exception as e:
        import traceback
        logger.error(f"ì—ëŸ¬ ë°œìƒ: {e}\n{traceback.format_exc()}")
        return [{
            "type": "text",
            "text": f"âŒ ì—ëŸ¬: {str(e)}\n\n{traceback.format_exc()}"
        }]


# ============================================
# Tool 7: í”„ë¡œì‹œì €/í•¨ìˆ˜ ëª©ë¡
# ============================================

async def show_procedures(
    database_sid: str,
    schema_name: str
) -> list[dict]:
    """í”„ë¡œì‹œì € ë° í•¨ìˆ˜ ëª©ë¡"""
    try:
        connector = get_connector(database_sid)
        procedures = connector.list_procedures(schema_name)

        result_text = f"âš™ï¸ {database_sid}.{schema_name}ì˜ í”„ë¡œì‹œì €/í•¨ìˆ˜ ({len(procedures)}ê°œ)\n\n"

        for proc in procedures:
            result_text += f"- {proc['OBJECT_NAME']} ({proc['OBJECT_TYPE']})\n"
            result_text += f"  ìƒíƒœ: {proc['STATUS']}, ìˆ˜ì •ì¼: {proc['LAST_DDL_TIME']}\n\n"

        return [{"type": "text", "text": result_text}]

    except Exception as e:
        import traceback
        logger.error(f"ì—ëŸ¬ ë°œìƒ: {e}\n{traceback.format_exc()}")
        return [{
            "type": "text",
            "text": f"âŒ ì—ëŸ¬: {str(e)}\n\n{traceback.format_exc()}"
        }]


# ============================================
# Tool 8: í”„ë¡œì‹œì € ì†ŒìŠ¤ ì½”ë“œ
# ============================================

async def show_procedure_source(
    database_sid: str,
    schema_name: str,
    procedure_name: str
) -> list[dict]:
    """í”„ë¡œì‹œì €/í•¨ìˆ˜ ì†ŒìŠ¤ ì½”ë“œ"""
    try:
        connector = get_connector(database_sid)
        source = connector.get_procedure_source(schema_name, procedure_name)

        if not source:
            return [{
                "type": "text",
                "text": f"í”„ë¡œì‹œì €ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {procedure_name}"
            }]

        result_text = f"ğŸ“„ í”„ë¡œì‹œì € ì†ŒìŠ¤: {database_sid}.{schema_name}.{procedure_name}\n\n"
        result_text += "```sql\n"
        result_text += source
        result_text += "\n```"

        return [{"type": "text", "text": result_text}]

    except Exception as e:
        import traceback
        logger.error(f"ì—ëŸ¬ ë°œìƒ: {e}\n{traceback.format_exc()}")
        return [{
            "type": "text",
            "text": f"âŒ ì—ëŸ¬: {str(e)}\n\n{traceback.format_exc()}"
        }]


# ============================================
# Tool 9: SQL ì§ì ‘ ì‹¤í–‰
# ============================================

async def execute_sql(
    database_sid: str,
    sql: str,
    max_rows: int = 1000
) -> list[dict]:
    """SQL ì¿¼ë¦¬ ì§ì ‘ ì‹¤í–‰ (SELECTë§Œ)"""
    try:
        connector = get_connector(database_sid)
        executor = SQLExecutor(connector)

        result = executor.execute_select(sql, max_rows)

        if result['status'] == 'error':
            return [{
                "type": "text",
                "text": f"âŒ {result['message']}"
            }]

        result_text = f"âœ… ì¿¼ë¦¬ ì‹¤í–‰ ì™„ë£Œ\n\n"

        # ì¸ë±ìŠ¤ ìµœì í™” ê²€ì‚¬ ê²°ê³¼ í‘œì‹œ
        optimization_check = result.get('optimization_check', {})
        violations = optimization_check.get('violations', [])
        warnings = optimization_check.get('warnings', [])

        if violations or warnings:
            result_text += "## ğŸ” SQL ìµœì í™” ê²€ì‚¬\n\n"

            if violations:
                result_text += "### âŒ ìœ„ë°˜ ì‚¬í•­ (ë°˜ë“œì‹œ ìˆ˜ì • í•„ìš”)\n"
                for v in violations:
                    result_text += f"{v}\n\n"

            if warnings:
                result_text += "### âš ï¸ ê²½ê³  ì‚¬í•­ (ì„±ëŠ¥ì— ì˜í–¥ ê°€ëŠ¥)\n"
                for w in warnings:
                    result_text += f"{w}\n\n"

            result_text += "---\n\n"

        result_text += f"SQL:\n```sql\n{sql}\n```\n\n"
        result_text += f"ê²°ê³¼: {result['row_count']}ê°œ í–‰\n\n"

        # ê²°ê³¼ í…Œì´ë¸” í˜•ì‹ìœ¼ë¡œ
        if result['rows']:
            import json
            result_text += "```json\n"
            result_text += json.dumps(result['rows'][:10], ensure_ascii=False, indent=2)
            result_text += "\n```"

            if len(result['rows']) > 10:
                result_text += f"\n\n... ì™¸ {len(result['rows']) - 10}ê°œ í–‰"

        return [{"type": "text", "text": result_text}]

    except Exception as e:
        import traceback
        logger.error(f"SQL ì‹¤í–‰ ì‹¤íŒ¨: {e}\n{traceback.format_exc()}")
        return [{
            "type": "text",
            "text": f"âŒ SQL ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}\n\n{traceback.format_exc()}"
        }]


# ============================================
# Tool 10: ìì—°ì–´ ì¿¼ë¦¬ë¥¼ ìœ„í•œ í…Œì´ë¸” ìš”ì•½ ì œê³µ (Stage 1)
# ============================================

async def get_table_summaries_for_query(
    database_sid: str,
    schema_name: str,
    natural_query: str = ""
) -> list[dict]:
    """
    Vector DB ê¸°ë°˜ í…Œì´ë¸” ìš”ì•½ ì •ë³´ ì œê³µ (Stage 1)

    Backend ì—†ì´ vector_db/ í´ë”ì—ì„œ ì§ì ‘ ChromaDB ì½ê¸°
    ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ìœ¼ë¡œ ê´€ë ¨ í…Œì´ë¸” ì°¾ê¸°
    """
    try:
        vector_db = get_vector_db()

        # Vector DB ì´ˆê¸°í™” í™•ì¸
        if not vector_db.is_available():
            return [{
                "type": "text",
                "text": (
                    "âŒ **Vector DBë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤**\n\n"
                    f"**Database**: {database_sid}\n"
                    f"**Schema**: {schema_name}\n\n"
                    "**ì›ì¸**: Vector DBê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n\n"
                    "**í•´ê²° ë°©ë²•**:\n"
                    "1. Backend ì„œë²„ë¥¼ ì‹œì‘í•˜ì—¬ ë°ì´í„°ë¥¼ í•™ìŠµì‹œí‚¤ì„¸ìš”:\n"
                    "   ```bash\n"
                    "   cd backend\n"
                    "   python -m uvicorn app.main:app --reload\n"
                    "   ```\n\n"
                    "2. Web UIì—ì„œ ë©”íƒ€ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”:\n"
                    "   - ì£¼ì†Œ: http://localhost:3000\n"
                    "   - CSV íŒŒì¼ ì—…ë¡œë“œ ë˜ëŠ” JSON ë§ˆì´ê·¸ë ˆì´ì…˜\n\n"
                    "3. í•™ìŠµ ì™„ë£Œ í›„ Backendë¥¼ ì¢…ë£Œí•´ë„ ë©ë‹ˆë‹¤.\n"
                    "   MCP ì„œë²„ëŠ” vector_db/ í´ë”ë¥¼ ì§ì ‘ ì½ì–´ ë…ë¦½ ë™ì‘í•©ë‹ˆë‹¤.\n\n"
                    "ğŸ’¡ **ì°¸ê³ **: í•™ìŠµì€ í•œ ë²ˆë§Œ í•˜ë©´ ë©ë‹ˆë‹¤."
                )
            }]

        # Vector DBì—ì„œ ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰
        tables = vector_db.search_tables(
            question=natural_query,
            database_sid=database_sid,
            schema_name=schema_name,
            n_results=10
        )

        if not tables:
            return [{
                "type": "text",
                "text": (
                    f"â„¹ï¸ **ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤**\n\n"
                    f"**ì§ˆë¬¸**: {natural_query}\n"
                    f"**Database**: {database_sid}\n"
                    f"**Schema**: {schema_name}\n\n"
                    "ì´ ìŠ¤í‚¤ë§ˆì— ëŒ€í•œ ë°ì´í„°ê°€ Vector DBì— ì—†ìŠµë‹ˆë‹¤.\n"
                    "Backendë¥¼ í†µí•´ ë¨¼ì € í•™ìŠµì‹œì¼œì£¼ì„¸ìš”."
                )
            }]

        # ê²°ê³¼ í¬ë§·íŒ…
        result_text = f"ğŸ“Š **í…Œì´ë¸” ê²€ìƒ‰ ê²°ê³¼** (Vector DB)\n\n"
        result_text += f"**ì§ˆë¬¸**: {natural_query}\n\n"
        result_text += f"**Database**: {database_sid}\n"
        result_text += f"**Schema**: {schema_name}\n"
        result_text += f"**ê²€ìƒ‰ ë°©ì‹**: ğŸš€ ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ (ChromaDB)\n"
        result_text += f"**ë°œê²¬ëœ í…Œì´ë¸”**: {len(tables)}ê°œ\n\n"
        result_text += "**ê´€ë ¨ í…Œì´ë¸” ëª©ë¡** (ê´€ë ¨ë„ ìˆœ):\n\n"

        for i, table in enumerate(tables, 1):
            similarity_pct = table["similarity"] * 100
            result_text += f"### {i}. {table['table_name']} "
            result_text += f"(ê´€ë ¨ë„: {similarity_pct:.1f}%)\n"

            if table.get("korean_name"):
                result_text += f"- **í•œê¸€ëª…**: {table['korean_name']}\n"

            if table.get("description"):
                desc = table['description'][:100]
                if len(table['description']) > 100:
                    desc += "..."
                result_text += f"- **ì„¤ëª…**: {desc}\n"

            result_text += f"- **ì»¬ëŸ¼ ìˆ˜**: {table['column_count']}\n\n"

        result_text += "---\n\n"
        result_text += "**ë‹¤ìŒ ë‹¨ê³„**:\n"
        result_text += "1. ìœ„ í…Œì´ë¸”ë“¤ ì¤‘ í•„ìš”í•œ í…Œì´ë¸” ì„ íƒ (ìµœëŒ€ 5ê°œ ê¶Œì¥)\n"
        result_text += "2. `get_detailed_metadata_for_sql` Tool í˜¸ì¶œ\n"
        result_text += "3. ìƒì„¸ ë©”íƒ€ë°ì´í„°ë¡œ SQL ìƒì„±\n\n"
        result_text += "ğŸ’¡ **TIP**: ê´€ë ¨ë„ê°€ ë†’ì€(>70%) í…Œì´ë¸”ë¶€í„° ì„ íƒí•˜ì„¸ìš”."

        return [{"type": "text", "text": result_text}]

    except RuntimeError as e:
        logger.error(f"Vector DB error: {e}")
        return [{
            "type": "text",
            "text": f"âŒ Vector DB ì˜¤ë¥˜: {str(e)}"
        }]

    except Exception as e:
        import traceback
        logger.error(f"í…Œì´ë¸” ê²€ìƒ‰ ì‹¤íŒ¨: {e}\n{traceback.format_exc()}")
        return [{
            "type": "text",
            "text": f"âŒ í…Œì´ë¸” ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}"
        }]


# ============================================
# Tool 10-1: Vector DB ìƒíƒœ í™•ì¸
# ============================================

async def check_vectordb_status() -> list[dict]:
    """Vector DB ìƒíƒœ í™•ì¸ ë„êµ¬"""
    try:
        vector_db = get_vector_db()

        if vector_db.is_available():
            stats = vector_db.get_stats()

            result_text = "âœ… **Vector DB ì •ìƒ ë™ì‘ ì¤‘**\n\n"
            result_text += f"**ìœ„ì¹˜**: vector_db/\n"
            result_text += f"**í…Œì´ë¸” ìˆ˜**: {stats['table_count']}ê°œ\n"
            result_text += "**ìƒíƒœ**: ì‚¬ìš© ê°€ëŠ¥\n"
            result_text += "**Backend**: ë¶ˆí•„ìš” (ì´ë¯¸ í•™ìŠµ ì™„ë£Œ)\n\n"
            result_text += "**ì‚¬ìš© ê°€ëŠ¥í•œ ê¸°ëŠ¥**:\n"
            result_text += "- âœ… ì˜ë¯¸ ê¸°ë°˜ í…Œì´ë¸” ê²€ìƒ‰\n"
            result_text += "- âœ… SQL ìƒì„± ë° ì‹¤í–‰\n"
            result_text += "- âœ… ë©”íƒ€ë°ì´í„° ì¡°íšŒ\n\n"
            result_text += "ğŸ’¡ MCP ì„œë²„ê°€ ë…ë¦½ì ìœ¼ë¡œ ë™ì‘ ì¤‘ì…ë‹ˆë‹¤."
        else:
            result_text = "âš ï¸ **Vector DB ì´ˆê¸°í™” í•„ìš”**\n\n"
            result_text += "**ìƒíƒœ**: ì‚¬ìš© ë¶ˆê°€\n"
            result_text += "**ì›ì¸**: vector_db/ ë””ë ‰í† ë¦¬ê°€ ì—†ê±°ë‚˜ ë¹„ì–´ìˆìŒ\n\n"
            result_text += "**ì´ˆê¸°í™” ë°©ë²•**:\n"
            result_text += "1. Backend ì„œë²„ ì‹œì‘\n"
            result_text += "2. CSV/JSON ì—…ë¡œë“œë¡œ ë©”íƒ€ë°ì´í„° í•™ìŠµ\n"
            result_text += "3. Backend ì¢…ë£Œ (ì´í›„ ë¶ˆí•„ìš”)\n"
            result_text += "4. MCP ì„œë²„ ë…ë¦½ ì‹¤í–‰\n\n"
            result_text += "ğŸ’¡ í•™ìŠµì€ í•œ ë²ˆë§Œ í•˜ë©´ ë©ë‹ˆë‹¤."

        return [{"type": "text", "text": result_text}]

    except Exception as e:
        import traceback
        logger.error(f"ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}\n{traceback.format_exc()}")
        return [{"type": "text", "text": f"âŒ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {str(e)}"}]


# ============================================
# Tool 11: ì„ íƒëœ í…Œì´ë¸”ë“¤ì˜ ìƒì„¸ ë©”íƒ€ë°ì´í„° ì œê³µ (Stage 2)
# ============================================

async def get_detailed_metadata_for_sql(
    database_sid: str,
    schema_name: str,
    table_names: str,  # ì‰¼í‘œë¡œ êµ¬ë¶„ëœ í…Œì´ë¸”ëª…
    natural_query: str = ""
) -> list[dict]:
    """
    ì„ íƒëœ í…Œì´ë¸”ë“¤ì˜ ìƒì„¸ ë©”íƒ€ë°ì´í„° ì œê³µ (Stage 2)

    Claudeê°€ ì´ ì •ë³´ë¥¼ ë³´ê³  ì •í™•í•œ SQLì„ ìƒì„±í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
    """
    try:
        # í…Œì´ë¸”ëª… íŒŒì‹±
        selected_tables = [t.strip() for t in table_names.split(',')]

        if len(selected_tables) > 5:
            return [{
                "type": "text",
                "text": f"âš ï¸ í…Œì´ë¸”ì€ ìµœëŒ€ 5ê°œê¹Œì§€ë§Œ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (í˜„ì¬: {len(selected_tables)}ê°œ)"
            }]

        import json
        result_text = f"ğŸ“Š ìƒì„¸ ë©”íƒ€ë°ì´í„° (Stage 2)\n\n"
        result_text += f"**ì§ˆë¬¸**: {natural_query}\n\n"
        result_text += f"**ì„ íƒëœ í…Œì´ë¸”**: {', '.join(selected_tables)}\n\n"
        result_text += "---\n\n"

        # ê° í…Œì´ë¸”ì˜ ìƒì„¸ ë©”íƒ€ë°ì´í„° ë¡œë“œ
        all_metadata = []
        for table_name in selected_tables:
            try:
                metadata = metadata_manager.load_unified_metadata(
                    database_sid, schema_name, table_name
                )
                all_metadata.append(metadata)

                # ê°„ë‹¨í•œ ìš”ì•½ í‘œì‹œ
                result_text += f"### {table_name}\n"
                result_text += f"- ëª©ì : {metadata.get('table_info', {}).get('business_purpose', 'N/A')}\n"
                result_text += f"- ì¹¼ëŸ¼ ìˆ˜: {len(metadata.get('columns', []))}\n\n"

            except FileNotFoundError:
                result_text += f"### {table_name}\n"
                result_text += f"âš ï¸ ë©”íƒ€ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n"

        # ì „ì²´ ë©”íƒ€ë°ì´í„° JSON ì œê³µ
        result_text += "\n---\n\n"
        result_text += "**ì „ì²´ ë©”íƒ€ë°ì´í„° (SQL ìƒì„±ìš©)**:\n\n"
        result_text += "```json\n"
        result_text += json.dumps(all_metadata, ensure_ascii=False, indent=2)
        result_text += "\n```\n\n"

        result_text += "---\n\n"
        result_text += "**ë‹¤ìŒ ë‹¨ê³„**: ìœ„ ë©”íƒ€ë°ì´í„°ë¥¼ ì°¸ê³ í•˜ì—¬ Oracle SQLì„ ìƒì„±í•œ í›„,\n"
        result_text += "`execute_sql` Toolì„ í˜¸ì¶œí•˜ì—¬ ì‹¤í–‰í•˜ì„¸ìš”.\n\n"
        result_text += "**Oracle SQL ìƒì„± ê°€ì´ë“œ**:\n"
        result_text += "- Schema.Table í˜•ì‹ ì‚¬ìš© (ì˜ˆ: SCOTT.ORDERS)\n"
        result_text += "- Oracle ë‚ ì§œ í•¨ìˆ˜ ì‚¬ìš© (TRUNC, ADD_MONTHS, TO_CHAR ë“±)\n"
        result_text += "- ì½”ë“œ ì¹¼ëŸ¼ì˜ ê²½ìš° ì½”ë“œê°’ìœ¼ë¡œ WHERE ì¡°ê±´ ì‘ì„±\n"
        result_text += "- FK ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ì •í™•í•œ JOIN ì¡°ê±´ ì‘ì„±\n"

        return [{"type": "text", "text": result_text}]

    except Exception as e:
        import traceback
        logger.error(f"ìƒì„¸ ë©”íƒ€ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}\n{traceback.format_exc()}")
        return [{
            "type": "text",
            "text": f"âŒ ìƒì„¸ ë©”íƒ€ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {str(e)}\n\n{traceback.format_exc()}"
        }]




# ============================================
# Tool 12: í…Œì´ë¸” ë©”íƒ€ì •ë³´ ì¡°íšŒ
# ============================================

async def get_table_metadata(
    database_sid: str,
    schema_name: str,
    table_name: str
) -> list[dict]:
    """í†µí•© ë©”íƒ€ì •ë³´ ì¡°íšŒ"""
    try:
        metadata = metadata_manager.load_unified_metadata(
            database_sid, schema_name, table_name
        )

        import json
        result_text = f"ğŸ“Š í†µí•© ë©”íƒ€ì •ë³´: {database_sid}.{schema_name}.{table_name}\n\n"
        result_text += "```json\n"
        result_text += json.dumps(metadata, ensure_ascii=False, indent=2)
        result_text += "\n```"

        return [{"type": "text", "text": result_text}]

    except FileNotFoundError:
        return [{
            "type": "text",
            "text": f"âŒ ë©”íƒ€ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤: {database_sid}.{schema_name}.{table_name}"
        }]
    except Exception as e:
        import traceback
        logger.error(f"ì—ëŸ¬ ë°œìƒ: {e}\n{traceback.format_exc()}")
        return [{
            "type": "text",
            "text": f"âŒ ì—ëŸ¬: {str(e)}\n\n{traceback.format_exc()}"
        }]


# ============================================
# Tool: SQL ê·œì¹™ ì¡°íšŒ
# ============================================

async def view_sql_rules() -> list[dict]:
    """í˜„ì¬ ì„¤ì •ëœ SQL ì‘ì„± ê·œì¹™ ì¡°íšŒ"""
    try:
        from pathlib import Path

        # data/sql_rules.md ê³µìœ  íŒŒì¼ ì‚¬ìš©
        sql_rules_path = data_dir / "sql_rules.md"

        if not sql_rules_path.exists():
            return [{
                "type": "text",
                "text": "âŒ SQL ê·œì¹™ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\n`update_sql_rules` Toolì„ ì‚¬ìš©í•˜ì—¬ ê·œì¹™ì„ ìƒì„±í•˜ì„¸ìš”."
            }]

        with open(sql_rules_path, 'r', encoding='utf-8') as f:
            rules_content = f.read()

        result_text = "ğŸ“‹ í˜„ì¬ SQL ì‘ì„± ê·œì¹™\n\n"
        result_text += f"**íŒŒì¼ ìœ„ì¹˜**: {sql_rules_path}\n\n"
        result_text += "---\n\n"
        result_text += rules_content

        return [{"type": "text", "text": result_text}]

    except Exception as e:
        import traceback
        logger.error(f"SQL ê·œì¹™ ì¡°íšŒ ì‹¤íŒ¨: {e}\n{traceback.format_exc()}")
        return [{
            "type": "text",
            "text": f"âŒ SQL ê·œì¹™ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}\n\n{traceback.format_exc()}"
        }]


# ============================================
# Tool: SQL ê·œì¹™ ì—…ë°ì´íŠ¸
# ============================================

async def update_sql_rules(rules_content: str) -> list[dict]:
    """SQL ì‘ì„± ê·œì¹™ ì—…ë°ì´íŠ¸"""
    try:
        from pathlib import Path

        # data/sql_rules.md ê³µìœ  íŒŒì¼ ì‚¬ìš©
        sql_rules_path = data_dir / "sql_rules.md"
        backup_dir = data_dir / "sql_rules_backups"

        # ë°±ì—… ë””ë ‰í† ë¦¬ ìƒì„±
        backup_dir.mkdir(exist_ok=True)

        # ë°±ì—… ìƒì„± (ê¸°ì¡´ íŒŒì¼ì´ ìˆëŠ” ê²½ìš°)
        if sql_rules_path.exists():
            import shutil
            from datetime import datetime
            backup_file = f'sql_rules_{datetime.now().strftime("%Y%m%d_%H%M%S")}.md'
            backup_path = backup_dir / backup_file
            shutil.copy2(sql_rules_path, backup_path)
            backup_msg = f"âœ… ê¸°ì¡´ ê·œì¹™ ë°±ì—…: {backup_file}\n"
        else:
            backup_msg = ""

        # ìƒˆ ê·œì¹™ ì €ì¥
        with open(sql_rules_path, 'w', encoding='utf-8') as f:
            f.write(rules_content)

        result_text = "âœ… SQL ì‘ì„± ê·œì¹™ ì—…ë°ì´íŠ¸ ì™„ë£Œ\n\n"
        result_text += backup_msg
        result_text += f"**íŒŒì¼ ìœ„ì¹˜**: {sql_rules_path}\n"
        result_text += f"**ê·œì¹™ ê¸¸ì´**: {len(rules_content)} ì\n\n"
        result_text += "---\n\n"
        result_text += "**ì—…ë°ì´íŠ¸ëœ ê·œì¹™ ë¯¸ë¦¬ë³´ê¸°**:\n\n"
        result_text += rules_content[:500]
        if len(rules_content) > 500:
            result_text += "\n\n... (ìƒëµ)"

        return [{"type": "text", "text": result_text}]

    except Exception as e:
        import traceback
        logger.error(f"SQL ê·œì¹™ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}\n{traceback.format_exc()}")
        return [{
            "type": "text",
            "text": f"âŒ SQL ê·œì¹™ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}\n\n{traceback.format_exc()}"
        }]


# ============================================
# Tool: ìì—°ì–´ë¡œ ì»¬ëŸ¼ ê²€ìƒ‰ (ì˜ë¯¸ ê¸°ë°˜)
# ============================================

async def search_columns(
    database_sid: str,
    schema_name: str,
    query: str,
    table_name: str = None,
    n_results: int = 10
) -> list[dict]:
    """
    â˜… ìì—°ì–´ë¡œ ì»¬ëŸ¼ ê²€ìƒ‰ (Vector DB ê¸°ë°˜ ì˜ë¯¸ ê²€ìƒ‰)

    ì‚¬ìš©ìì˜ ìì—°ì–´ ì§ˆë¬¸ì„ ë²¡í„°ë¡œ ë³€í™˜í•˜ì—¬
    ê°€ì¥ ê´€ë ¨ ìˆëŠ” Oracle ì»¬ëŸ¼ë“¤ì„ ì°¾ì•„ì¤ë‹ˆë‹¤.

    Args:
        database_sid: Database SID
        schema_name: ìŠ¤í‚¤ë§ˆ ì´ë¦„
        query: ìì—°ì–´ ê²€ìƒ‰ì–´ (ì˜ˆ: "ë¼ì¸", "ì¼ì", "ìˆ˜ëŸ‰", "ëª¨ë¸ëª…")
        table_name: íŠ¹ì • í…Œì´ë¸”ë¡œ ì œí•œ (ì„ íƒ)
        n_results: ë°˜í™˜í•  ì»¬ëŸ¼ ìˆ˜ (ê¸°ë³¸ê°’: 10)

    Returns:
        ê´€ë ¨ ì»¬ëŸ¼ ì •ë³´ ë¦¬ìŠ¤íŠ¸
    """
    try:
        vector_db = get_vector_db()

        # Vector DB ì»¬ëŸ¼ ì»¬ë ‰ì…˜ í™•ì¸
        if vector_db.columns_collection is None:
            return [{
                "type": "text",
                "text": (
                    "âŒ **ì»¬ëŸ¼ Vector DBë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤**\n\n"
                    f"**Database**: {database_sid}\n"
                    f"**Schema**: {schema_name}\n"
                    f"**ê²€ìƒ‰ì–´**: {query}\n\n"
                    "**ì›ì¸**: ì»¬ëŸ¼ ë²¡í„°í™”ê°€ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n\n"
                    "**í•´ê²° ë°©ë²•**:\n"
                    "1. ë£¨íŠ¸ ë””ë ‰í† ë¦¬ì—ì„œ ì»¬ëŸ¼ ë²¡í„°í™” ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰:\n"
                    "   ```bash\n"
                    "   python vectorize_columns.py\n"
                    "   ```\n\n"
                    "2. ë²¡í„°í™” ì™„ë£Œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.\n"
                    "   (21,515ê°œ ì»¬ëŸ¼ì„ ë²¡í„°í™”í•˜ëŠ” ë° ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)\n\n"
                    "ğŸ’¡ **ì°¸ê³ **: ì´í›„ì—ëŠ” ìë™ìœ¼ë¡œ ì§„í–‰ ìƒí™©ì„ ì¶”ì í•˜ì—¬ ë¹ ë¥´ê²Œ ì²˜ë¦¬ë©ë‹ˆë‹¤."
                )
            }]

        # ì»¬ëŸ¼ ê²€ìƒ‰ ìˆ˜í–‰
        columns = vector_db.search_columns(
            query=query,
            database_sid=database_sid,
            schema_name=schema_name,
            table_name=table_name,
            n_results=n_results
        )

        if not columns:
            return [{
                "type": "text",
                "text": (
                    f"â„¹ï¸ **ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤**\n\n"
                    f"**ê²€ìƒ‰ì–´**: {query}\n"
                    f"**Database**: {database_sid}\n"
                    f"**Schema**: {schema_name}\n"
                    f"{'**í…Œì´ë¸”**: ' + table_name if table_name else ''}\n\n"
                    "ì´ ì¡°ê±´ì— ë§ëŠ” ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.\n"
                    "ë‹¤ë¥¸ ê²€ìƒ‰ì–´ë¡œ ì‹œë„í•´ë³´ì„¸ìš”."
                )
            }]

        # ê²°ê³¼ í¬ë§·íŒ…
        result_text = f"ğŸ” **ì»¬ëŸ¼ ê²€ìƒ‰ ê²°ê³¼** (ì˜ë¯¸ ê¸°ë°˜)\n\n"
        result_text += f"**ê²€ìƒ‰ì–´**: {query}\n"
        result_text += f"**Database**: {database_sid}\n"
        result_text += f"**Schema**: {schema_name}\n"
        if table_name:
            result_text += f"**í…Œì´ë¸”**: {table_name}\n"
        result_text += f"**ë°œê²¬ëœ ì»¬ëŸ¼**: {len(columns)}ê°œ\n\n"
        result_text += "**ê²€ìƒ‰ ê²°ê³¼ (ìœ ì‚¬ë„ ìˆœ)**:\n\n"

        for i, col in enumerate(columns, 1):
            result_text += f"### {i}. {col['table_name']}.{col['column_name']}"
            if col.get('is_pk'):
                result_text += " [PK]"
            result_text += f" ({col['similarity']}% ìœ ì‚¬ë„)\n"

            if col.get('korean_name'):
                result_text += f"- **í•œê¸€ëª…**: {col['korean_name']}\n"

            if col.get('data_type'):
                result_text += f"- **ë°ì´í„°íƒ€ì…**: {col['data_type']}\n"

            if col.get('description'):
                desc = col['description'][:100]
                if len(col['description']) > 100:
                    desc += "..."
                result_text += f"- **ì„¤ëª…**: {desc}\n"

            if col.get('column_comment'):
                result_text += f"- **ì»¬ëŸ¼ ì£¼ì„**: {col['column_comment']}\n"

            result_text += "\n"

        result_text += "---\n\n"
        result_text += "**ë‹¤ìŒ ë‹¨ê³„**:\n"
        result_text += "1. ìœ„ ì»¬ëŸ¼ë“¤ì„ SELECT ì ˆì— í¬í•¨ì‹œì¼œ SQL ì‘ì„±\n"
        result_text += "2. `execute_sql` Toolë¡œ SQL ì‹¤í–‰\n\n"
        result_text += "ğŸ’¡ **TIP**: ìœ ì‚¬ë„ê°€ ë†’ì€(>70%) ì»¬ëŸ¼ë¶€í„° ì„ íƒí•˜ì„¸ìš”."

        return [{
            "type": "text",
            "text": result_text
        }]

    except RuntimeError as e:
        logger.error(f"Vector DB error: {e}")
        return [{
            "type": "text",
            "text": f"âŒ Vector DB ì˜¤ë¥˜: {str(e)}"
        }]

    except Exception as e:
        import traceback
        logger.error(f"ì»¬ëŸ¼ ê²€ìƒ‰ ì‹¤íŒ¨: {e}\n{traceback.format_exc()}")
        return [{
            "type": "text",
            "text": f"âŒ ì»¬ëŸ¼ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}\n\n{traceback.format_exc()}"
        }]


# ============================================
# Tool: SQL ìƒì„± ë° ë¯¸ë¦¬ë³´ê¸° (í”¼ë“œë°± í¬í•¨)
# ============================================

async def generate_and_review_sql(
    database_sid: str,
    schema_name: str,
    natural_query: str,
    created_by: str = "system"
) -> list[dict]:
    """
    â˜… SQL ìƒì„± í›„ ë¯¸ë¦¬ë³´ê¸° (ì‚¬ìš©ì ê²€í†  ê¸°ëŠ¥)

    ìì—°ì–´ ì§ˆë¬¸ì„ ë°›ì•„ SQLì„ ìƒì„±í•˜ê³ , ë¯¸ë¦¬ë³´ê¸°ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    ì‚¬ìš©ìê°€ ê²€í†  í›„ í”¼ë“œë°±ì„ ì œì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """
    try:
        # Step 1: Vector DBë¡œ ê´€ë ¨ í…Œì´ë¸”/ì»¬ëŸ¼ ê²€ìƒ‰
        vector_db = get_vector_db()
        if not vector_db.is_available():
            return [{
                "type": "text",
                "text": "âŒ Vector DBë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë²¡í„°í™”ë¥¼ ì™„ë£Œí•˜ì„¸ìš”."
            }]

        # í…Œì´ë¸” ê²€ìƒ‰ (ê°€ì¤‘ì¹˜ ì ìš©)
        table_weights = feedback_manager.get_table_weights(database_sid, schema_name)
        tables = vector_db.search_tables(
            question=natural_query,
            database_sid=database_sid,
            schema_name=schema_name,
            n_results=5,
            weights=table_weights if table_weights else None
        )

        if not tables:
            return [{
                "type": "text",
                "text": f"âŒ ê´€ë ¨ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\nìì—°ì–´: {natural_query}"
            }]

        # ì„ íƒëœ í…Œì´ë¸” ì •ë³´
        selected_table = tables[0]
        table_name = selected_table["table_name"]

        # ì»¬ëŸ¼ ê²€ìƒ‰
        column_weights = feedback_manager.get_column_weights(
            table_name, database_sid, schema_name
        )
        columns = vector_db.search_columns(
            query=natural_query,
            database_sid=database_sid,
            schema_name=schema_name,
            table_name=table_name,
            n_results=10,
            column_weights={table_name: column_weights} if column_weights else None
        )

        # Step 2: Claudeë¡œ SQL ìƒì„± (ê°„ë‹¨í•œ ì¿¼ë¦¬)
        # ì—¬ê¸°ì„œëŠ” ê¸°ë³¸ SELECT êµ¬ë¬¸ ìƒì„±
        selected_columns = [col["column_name"] for col in columns[:5]]
        if not selected_columns:
            selected_columns = ["*"]

        columns_clause = ", ".join(selected_columns)
        generated_sql = f"SELECT {columns_clause} FROM {schema_name}.{table_name}"

        # Step 3: í”¼ë“œë°± ì €ì¥ (SQL ìƒì„± ì´ë ¥)
        feedback_data = {
            "user_query": natural_query,
            "selected_table": table_name,
            "selected_columns": selected_columns,
            "generated_sql": generated_sql,
            "database_sid": database_sid,
            "schema_name": schema_name,
            "created_by": created_by
        }

        feedback_id = feedback_manager.save_sql_generation(feedback_data)

        # Step 4: ë¯¸ë¦¬ë³´ê¸° í˜•ì‹ìœ¼ë¡œ ë°˜í™˜
        result_text = f"ğŸ” **SQL ìƒì„± ì™„ë£Œ** (ID: {feedback_id})\n\n"
        result_text += f"**ì‚¬ìš©ì ì§ˆë¬¸**: {natural_query}\n\n"
        result_text += f"**ì„ íƒëœ í…Œì´ë¸”**: {table_name}\n"
        result_text += f"**í…Œì´ë¸” ìœ ì‚¬ë„**: {selected_table.get('similarity', 0):.1f}%\n\n"

        result_text += "**ê²€ìƒ‰ëœ ì»¬ëŸ¼** (ìƒìœ„ 5ê°œ):\n"
        for i, col in enumerate(columns[:5], 1):
            result_text += f"- {i}. {col['column_name']} ({col.get('similarity', 0):.1f}% ìœ ì‚¬ë„)\n"

        result_text += f"\n**ìƒì„±ëœ SQL**:\n```sql\n{generated_sql}\n```\n\n"

        result_text += f"**ë‹¤ìŒ ë‹¨ê³„**:\n"
        result_text += f"1. `submit_sql_feedback` Toolì„ ì‚¬ìš©í•˜ì—¬ ë‹¤ìŒ ì¤‘ ì„ íƒ:\n"
        result_text += f"   - action: 'approve' (ìŠ¹ì¸ í›„ ì‹¤í–‰)\n"
        result_text += f"   - action: 'modify' (ìˆ˜ì • ì œì•ˆ í›„ ì¬ìƒì„±)\n"
        result_text += f"   - action: 'reject' (ê±°ë¶€)\n\n"
        result_text += f"**Feedback ID**: `{feedback_id}`\n"

        return [{"type": "text", "text": result_text}]

    except Exception as e:
        import traceback
        logger.error(f"SQL ìƒì„± ì‹¤íŒ¨: {e}\n{traceback.format_exc()}")
        return [{
            "type": "text",
            "text": f"âŒ SQL ìƒì„± ì‹¤íŒ¨: {str(e)}\n\n{traceback.format_exc()}"
        }]


# ============================================
# Tool: ì‚¬ìš©ì í”¼ë“œë°± ì €ì¥ ë° ê°€ì¤‘ì¹˜ ê³„ì‚°
# ============================================

async def submit_sql_feedback(
    feedback_id: str,
    action: str,
    suggestions: str = None,
    user_confidence: float = 0.5
) -> list[dict]:
    """
    â˜… ì‚¬ìš©ì í”¼ë“œë°± ì €ì¥ ë° ê°€ì¤‘ì¹˜ ê³„ì‚°

    action: 'approve', 'modify', 'reject'
    """
    try:
        # Step 1: ì‚¬ìš©ì í”¼ë“œë°± ì €ì¥
        feedback_manager.save_user_feedback(
            feedback_id=feedback_id,
            action=action,
            suggestions=suggestions,
            user_confidence=user_confidence
        )

        # Step 2: ê°€ì¤‘ì¹˜ ê³„ì‚°
        feedback_manager.calculate_weights()

        result_text = f"âœ… **í”¼ë“œë°± ì²˜ë¦¬ ì™„ë£Œ**\n\n"
        result_text += f"**Feedback ID**: {feedback_id}\n"
        result_text += f"**ì‚¬ìš©ì ì„ íƒ**: {action.upper()}\n"
        result_text += f"**ì‹ ë¢°ë„**: {user_confidence*100:.0f}%\n\n"

        if suggestions:
            result_text += f"**ì‚¬ìš©ì ì œì•ˆ**: {suggestions}\n\n"

        result_text += "âœ… ê°€ì¤‘ì¹˜ ì¬ê³„ì‚° ì™„ë£Œ\n"
        result_text += "ë‹¤ìŒ ê²€ìƒ‰ë¶€í„° ì‚¬ìš©ìì˜ í”¼ë“œë°±ì´ ë°˜ì˜ë©ë‹ˆë‹¤.\n\n"

        if action == "modify":
            result_text += "ğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:\n"
            result_text += "`regenerate_sql_with_feedback` Toolì„ ì‚¬ìš©í•˜ì—¬\n"
            result_text += "ì‚¬ìš©ì í”¼ë“œë°±ì„ ë°˜ì˜í•œ SQLì„ ì¬ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"

        return [{"type": "text", "text": result_text}]

    except Exception as e:
        import traceback
        logger.error(f"í”¼ë“œë°± ì €ì¥ ì‹¤íŒ¨: {e}\n{traceback.format_exc()}")
        return [{
            "type": "text",
            "text": f"âŒ í”¼ë“œë°± ì €ì¥ ì‹¤íŒ¨: {str(e)}\n\n{traceback.format_exc()}"
        }]


# ============================================
# Tool: í”¼ë“œë°± ê¸°ë°˜ SQL ì¬ìƒì„±
# ============================================

async def regenerate_sql_with_feedback(
    feedback_id: str,
    feedback_text: str
) -> list[dict]:
    """
    â˜… ì‚¬ìš©ì í”¼ë“œë°±ì„ ë°˜ì˜í•˜ì—¬ SQL ì¬ìƒì„±
    """
    try:
        # í”¼ë“œë°± ì •ë³´ ì¡°íšŒ
        feedback_summary = feedback_manager.query_feedback_summary(limit=100)

        # í•´ë‹¹ feedback_id ì°¾ê¸°
        target_feedback = None
        for fb in feedback_summary:
            if fb.get("feedback_id") == feedback_id:
                target_feedback = fb
                break

        if not target_feedback:
            return [{
                "type": "text",
                "text": f"âŒ Feedback IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {feedback_id}"
            }]

        # ì¬ìƒì„±ëœ SQL (ê°„ë‹¨í•œ ì˜ˆì‹œ)
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” Claudeì—ê²Œ í”¼ë“œë°±ì„ ì „ë‹¬í•˜ì—¬ SQL ì¬ìƒì„±
        regenerated_sql = f"-- í”¼ë“œë°± ë°˜ì˜ë¨: {feedback_text}\n"
        regenerated_sql += f"-- ì›ë³¸ Query: {target_feedback.get('user_query', '')}\n"
        regenerated_sql += "SELECT * FROM " + target_feedback.get('selected_table', 'TABLE')

        result_text = f"ğŸ”„ **SQL ì¬ìƒì„± ì™„ë£Œ**\n\n"
        result_text += f"**Feedback ID**: {feedback_id}\n"
        result_text += f"**ì‚¬ìš©ì í”¼ë“œë°±**: {feedback_text}\n\n"
        result_text += f"**ì¬ìƒì„±ëœ SQL**:\n```sql\n{regenerated_sql}\n```\n\n"
        result_text += "ğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:\n"
        result_text += "`execute_sql_direct` Toolì„ ì‚¬ìš©í•˜ì—¬ SQLì„ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"

        return [{"type": "text", "text": result_text}]

    except Exception as e:
        import traceback
        logger.error(f"SQL ì¬ìƒì„± ì‹¤íŒ¨: {e}\n{traceback.format_exc()}")
        return [{
            "type": "text",
            "text": f"âŒ SQL ì¬ìƒì„± ì‹¤íŒ¨: {str(e)}\n\n{traceback.format_exc()}"
        }]


# ============================================
# Tool: SQL ì§ì ‘ ì‹¤í–‰ (í”¼ë“œë°± ì—†ì´)
# ============================================

async def execute_sql_direct(
    database_sid: str,
    sql: str,
    max_rows: int = 100
) -> list[dict]:
    """SQLì„ ì§ì ‘ ì‹¤í–‰ (í”¼ë“œë°± ê¸°ëŠ¥ ì—†ìŒ)"""
    try:
        connector = get_connector(database_sid)

        # SQL ì‹¤í–‰
        results = connector.query(sql, max_rows=max_rows)

        if isinstance(results, str):
            return [{
                "type": "text",
                "text": f"âœ… **SQL ì‹¤í–‰ ì™„ë£Œ**\n\n{results}"
            }]

        # ê²°ê³¼ í¬ë§·íŒ…
        result_text = f"âœ… **SQL ì‹¤í–‰ ì™„ë£Œ** ({len(results)}í–‰)\n\n"
        result_text += "```\n"

        if results:
            # í—¤ë”
            headers = list(results[0].keys())
            header_line = " | ".join([f"{h[:15]:15}" for h in headers])
            result_text += header_line + "\n"
            result_text += "-" * len(header_line) + "\n"

            # ë°ì´í„°
            for row in results[:min(10, len(results))]:
                values = [str(row.get(h, ""))[:15] for h in headers]
                result_text += " | ".join([f"{v:15}" for v in values]) + "\n"

            if len(results) > 10:
                result_text += f"\n... ({len(results) - 10}ê°œ í–‰ ìƒëµ)\n"

        result_text += "```\n"

        return [{"type": "text", "text": result_text}]

    except Exception as e:
        import traceback
        logger.error(f"SQL ì‹¤í–‰ ì‹¤íŒ¨: {e}\n{traceback.format_exc()}")
        return [{
            "type": "text",
            "text": f"âŒ SQL ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}\n\n{traceback.format_exc()}"
        }]


# ============================================
# ì„œë²„ ì‹¤í–‰
# ============================================
async def main():
    """MCP ì„œë²„ ì‹¤í–‰"""
    logger.info("="*60)
    logger.info("ğŸš€ Oracle Database MCP ì„œë²„ ì‹œì‘")
    logger.info("="*60)

    async with stdio_server() as (read_stream, write_stream):
        await server.run(
            read_stream,
            write_stream,
            server.create_initialization_options()
        )


if __name__ == "__main__":
    import asyncio
    asyncio.run(main())
