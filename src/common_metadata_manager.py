"""
ê³µí†µ ë©”íƒ€ë°ì´í„° ê´€ë¦¬ì
ì‚¬ìš©ìê°€ ì œê³µí•˜ëŠ” ê³µí†µ ì¹¼ëŸ¼ ì •ë³´ì™€ ì½”ë“œ ì •ë³´ë¥¼ ê´€ë¦¬í•˜ê³  CSV ìƒì„±
"""

import json
import csv
from pathlib import Path
from typing import Dict, List, Optional
from datetime import datetime
import traceback


class CommonMetadataManager:
    """ê³µí†µ ë©”íƒ€ë°ì´í„° ê´€ë¦¬"""

    def __init__(self, base_dir: str = None):
        if base_dir:
            self.base_dir = Path(base_dir)
        else:
            self.base_dir = Path(__file__).parent.parent

        # ê³µí†µ ë©”íƒ€ë°ì´í„° ì €ì¥ í´ë” (DBë³„ë¡œ êµ¬ë¶„)
        self.common_metadata_dir = self.base_dir / "common_metadata"
        self.common_metadata_dir.mkdir(exist_ok=True)

    def _get_db_dir(self, database_sid: str) -> Path:
        """DBë³„ í´ë” ê²½ë¡œ"""
        db_dir = self.common_metadata_dir / database_sid
        db_dir.mkdir(exist_ok=True)
        return db_dir

    def _get_common_columns_file(self, database_sid: str) -> Path:
        """DBë³„ ê³µí†µ ì¹¼ëŸ¼ íŒŒì¼ ê²½ë¡œ"""
        return self._get_db_dir(database_sid) / "common_columns.json"

    def _get_code_definitions_file(self, database_sid: str) -> Path:
        """DBë³„ ì½”ë“œ ì •ì˜ íŒŒì¼ ê²½ë¡œ"""
        return self._get_db_dir(database_sid) / "code_definitions.json"

    # ============================================
    # ê³µí†µ ì¹¼ëŸ¼ ì •ë³´ ê´€ë¦¬
    # ============================================

    def save_common_columns(self, database_sid: str, columns: List[Dict]) -> bool:
        """
        ê³µí†µ ì¹¼ëŸ¼ ì •ë³´ ì €ì¥

        Args:
            columns: [
                {
                    'column_name': 'STATUS',
                    'korean_name': 'ìƒíƒœ',
                    'description': 'ì²˜ë¦¬ ìƒíƒœ ì½”ë“œ',
                    'is_code_column': True,
                    'sample_values': '01|02|03',
                    'business_rule': '01â†’02â†’03 ìˆœì„œë¡œ ì „ì´',
                    'unit': '',
                    'aggregation_functions': '',
                    'is_sensitive': False
                },
                ...
            ]
        """
        try:
            # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
            existing = self.load_common_columns(database_sid)

            # ì¹¼ëŸ¼ëª…ì„ í‚¤ë¡œ í•˜ëŠ” ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            columns_dict = {col['column_name']: col for col in columns}

            # ê¸°ì¡´ ë°ì´í„° ì—…ë°ì´íŠ¸
            existing.update(columns_dict)

            # ë©”íƒ€ë°ì´í„° ì¶”ê°€
            data = {
                'database_sid': database_sid,
                'last_updated': datetime.now().isoformat(),
                'column_count': len(existing),
                'columns': existing
            }

            # ì €ì¥
            file_path = self._get_common_columns_file(database_sid)
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)

            return True

        except Exception as e:
            print(f"ê³µí†µ ì¹¼ëŸ¼ ì •ë³´ ì €ì¥ ì‹¤íŒ¨: {e}\n{traceback.format_exc()}")
            return False

    def load_common_columns(self, database_sid: str) -> Dict[str, Dict]:
        """ê³µí†µ ì¹¼ëŸ¼ ì •ë³´ ë¡œë“œ"""
        file_path = self._get_common_columns_file(database_sid)
        if not file_path.exists():
            return {}

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return data.get('columns', {})
        except Exception as e:
            print(f"ê³µí†µ ì¹¼ëŸ¼ ì •ë³´ ë¡œë“œ ì‹¤íŒ¨: {e}\n{traceback.format_exc()}")
            return {}

    def get_column_info(self, database_sid: str, column_name: str) -> Optional[Dict]:
        """íŠ¹ì • ì¹¼ëŸ¼ ì •ë³´ ì¡°íšŒ"""
        columns = self.load_common_columns(database_sid)
        return columns.get(column_name)

    def delete_column(self, database_sid: str, column_name: str) -> bool:
        """ì¹¼ëŸ¼ ì •ë³´ ì‚­ì œ"""
        columns = self.load_common_columns(database_sid)
        if column_name in columns:
            del columns[column_name]

            data = {
                'database_sid': database_sid,
                'last_updated': datetime.now().isoformat(),
                'column_count': len(columns),
                'columns': columns
            }

            file_path = self._get_common_columns_file(database_sid)
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            return True
        return False

    # ============================================
    # ì½”ë“œ ì •ë³´ ê´€ë¦¬
    # ============================================

    def save_code_definitions(self, database_sid: str, codes: List[Dict]) -> bool:
        """
        ì½”ë“œ ì •ë³´ ì €ì¥

        Args:
            codes: [
                {
                    'column_name': 'STATUS',
                    'code_value': '01',
                    'code_label': 'ì ‘ìˆ˜',
                    'code_description': 'ì ‘ìˆ˜ëœ ìƒíƒœ',
                    'display_order': 1,
                    'is_active': True,
                    'parent_code': '',
                    'state_transition': '02'
                },
                ...
            ]
        """
        try:
            # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
            existing = self.load_code_definitions(database_sid)

            # ì¹¼ëŸ¼ëª…ë³„ë¡œ ê·¸ë£¹í™”
            for code in codes:
                column_name = code['column_name']
                code_value = code['code_value']

                if column_name not in existing:
                    existing[column_name] = {}

                existing[column_name][code_value] = code

            # ë©”íƒ€ë°ì´í„° ì¶”ê°€
            data = {
                'database_sid': database_sid,
                'last_updated': datetime.now().isoformat(),
                'code_column_count': len(existing),
                'definitions': existing
            }

            # ì €ì¥
            file_path = self._get_code_definitions_file(database_sid)
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)

            return True

        except Exception as e:
            print(f"ì½”ë“œ ì •ë³´ ì €ì¥ ì‹¤íŒ¨: {e}\n{traceback.format_exc()}")
            return False

    def load_code_definitions(self, database_sid: str) -> Dict[str, Dict[str, Dict]]:
        """ì½”ë“œ ì •ë³´ ë¡œë“œ"""
        file_path = self._get_code_definitions_file(database_sid)
        if not file_path.exists():
            return {}

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return data.get('definitions', {})
        except Exception as e:
            print(f"ì½”ë“œ ì •ë³´ ë¡œë“œ ì‹¤íŒ¨: {e}\n{traceback.format_exc()}")
            return {}

    def get_codes_for_column(self, database_sid: str, column_name: str) -> Dict[str, Dict]:
        """íŠ¹ì • ì¹¼ëŸ¼ì˜ ì½”ë“œ ëª©ë¡ ì¡°íšŒ"""
        definitions = self.load_code_definitions(database_sid)
        return definitions.get(column_name, {})

    def delete_code_column(self, database_sid: str, column_name: str) -> bool:
        """ì¹¼ëŸ¼ì˜ ëª¨ë“  ì½”ë“œ ì‚­ì œ"""
        definitions = self.load_code_definitions(database_sid)
        if column_name in definitions:
            del definitions[column_name]

            data = {
                'database_sid': database_sid,
                'last_updated': datetime.now().isoformat(),
                'code_column_count': len(definitions),
                'definitions': definitions
            }

            file_path = self._get_code_definitions_file(database_sid)
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            return True
        return False

    # ============================================
    # í…Œì´ë¸” ì •ë³´ ê´€ë¦¬
    # ============================================

    def save_table_info(self, database_sid: str, schema_name: str, tables_info: List[Dict]) -> bool:
        """
        í…Œì´ë¸” ì •ë³´ ì €ì¥

        Args:
            database_sid: Database SID
            schema_name: ìŠ¤í‚¤ë§ˆ ì´ë¦„
            tables_info: [
                {
                    'table_name': 'CUSTOMERS',
                    'business_purpose': 'ê³ ê° ì •ë³´ ê´€ë¦¬',
                    'usage_scenarios': ['ì‹œë‚˜ë¦¬ì˜¤1', 'ì‹œë‚˜ë¦¬ì˜¤2', 'ì‹œë‚˜ë¦¬ì˜¤3'],
                    'related_tables': ['ORDERS', 'ADDRESSES']
                },
                ...
            ]
        """
        try:
            # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
            existing = self.load_table_info(database_sid, schema_name)

            # í…Œì´ë¸”ëª…ì„ í‚¤ë¡œ í•˜ëŠ” ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            for table in tables_info:
                table_name = table['table_name']
                existing[table_name] = table

            # ë©”íƒ€ë°ì´í„° ì¶”ê°€
            data = {
                'database_sid': database_sid,
                'schema_name': schema_name,
                'last_updated': datetime.now().isoformat(),
                'table_count': len(existing),
                'tables': existing
            }

            # ì €ì¥
            file_path = self._get_table_info_file(database_sid, schema_name)
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)

            return True

        except Exception as e:
            print(f"í…Œì´ë¸” ì •ë³´ ì €ì¥ ì‹¤íŒ¨: {e}\n{traceback.format_exc()}")
            return False

    def load_table_info(self, database_sid: str, schema_name: str) -> Dict[str, Dict]:
        """í…Œì´ë¸” ì •ë³´ ë¡œë“œ"""
        file_path = self._get_table_info_file(database_sid, schema_name)
        if not file_path.exists():
            return {}

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return data.get('tables', {})
        except Exception as e:
            print(f"í…Œì´ë¸” ì •ë³´ ë¡œë“œ ì‹¤íŒ¨: {e}\n{traceback.format_exc()}")
            return {}

    def _get_table_info_file(self, database_sid: str, schema_name: str) -> Path:
        """DB/ìŠ¤í‚¤ë§ˆë³„ í…Œì´ë¸” ì •ë³´ íŒŒì¼ ê²½ë¡œ"""
        schema_dir = self._get_db_dir(database_sid) / schema_name
        schema_dir.mkdir(exist_ok=True)
        return schema_dir / "table_info.json"

    # ============================================
    # CSV ìƒì„±
    # ============================================

    def generate_csv_files(
        self,
        database_sid: str,
        schema_name: str,
        tables_columns: Dict[str, List[Dict]],
        output_dir: Path = None
    ) -> Dict[str, str]:
        """
        DB ìŠ¤í‚¤ë§ˆ ì •ë³´ + ê³µí†µ ë©”íƒ€ë°ì´í„° â†’ CSV íŒŒì¼ ìƒì„±

        Args:
            database_sid: Database SID
            schema_name: ìŠ¤í‚¤ë§ˆ ì´ë¦„
            tables_columns: {
                'TABLE_NAME': [
                    {'name': 'COLUMN_NAME', 'data_type': 'VARCHAR2(50)', 'nullable': 'Y', ...},
                    ...
                ],
                ...
            }
            output_dir: CSV ì €ì¥ ê²½ë¡œ (Noneì´ë©´ input/{DB_SID}/{SCHEMA}/)

        Returns:
            {
                'table_info': 'path/to/table_info.csv',
                'column_info': 'path/to/column_info.csv',
                'code_values': 'path/to/code_values.csv'
            }
        """
        if output_dir is None:
            output_dir = self.base_dir / "input" / database_sid / schema_name
        else:
            output_dir = Path(output_dir)

        output_dir.mkdir(parents=True, exist_ok=True)

        # ê³µí†µ ë©”íƒ€ë°ì´í„° ë¡œë“œ
        common_columns = self.load_common_columns()
        code_definitions = self.load_code_definitions()

        result = {}

        # 1. table_info.csv ìƒì„±
        table_info_path = output_dir / "table_info.csv"
        self._generate_table_info_csv(tables_columns.keys(), table_info_path)
        result['table_info'] = str(table_info_path)

        # 2. column_info.csv ìƒì„±
        column_info_path = output_dir / "column_info.csv"
        self._generate_column_info_csv(
            tables_columns, common_columns, column_info_path
        )
        result['column_info'] = str(column_info_path)

        # 3. code_values.csv ìƒì„±
        code_values_path = output_dir / "code_values.csv"
        self._generate_code_values_csv(
            tables_columns, code_definitions, code_values_path
        )
        result['code_values'] = str(code_values_path)

        return result

    def _generate_table_info_csv(self, table_names: List[str], output_path: Path):
        """table_info.csv ìƒì„± (í…œí”Œë¦¿, ì‚¬ìš©ìê°€ ì±„ì›Œì•¼ í•¨)"""
        with open(output_path, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.writer(f)

            # í—¤ë”
            writer.writerow([
                'table_name',
                'business_purpose',
                'usage_scenario_1',
                'usage_scenario_2',
                'usage_scenario_3',
                'related_tables'
            ])

            # ê° í…Œì´ë¸” (ë¹„ì›Œë‘  - ì‚¬ìš©ìê°€ ì±„ì›Œì•¼ í•¨)
            for table_name in sorted(table_names):
                writer.writerow([
                    table_name,
                    '',  # business_purpose (ì‚¬ìš©ì ì…ë ¥ í•„ìš”)
                    '',  # usage_scenario_1
                    '',  # usage_scenario_2
                    '',  # usage_scenario_3
                    ''   # related_tables
                ])

    def _generate_column_info_csv(
        self,
        tables_columns: Dict[str, List[Dict]],
        common_columns: Dict[str, Dict],
        output_path: Path
    ):
        """column_info.csv ìƒì„± (DB ì •ë³´ + ê³µí†µ ì¹¼ëŸ¼ ì •ë³´ ë§¤ì¹­)"""
        with open(output_path, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.writer(f)

            # í—¤ë”
            writer.writerow([
                'table_name',
                'column_name',
                'korean_name',
                'description',
                'business_rule',
                'sample_values',
                'unit',
                'is_code_column',
                'aggregation_functions',
                'is_sensitive'
            ])

            # ê° í…Œì´ë¸”ì˜ ì¹¼ëŸ¼
            for table_name in sorted(tables_columns.keys()):
                columns = tables_columns[table_name]

                for col in columns:
                    column_name = col['name']

                    # ê³µí†µ ì¹¼ëŸ¼ ì •ë³´ ë§¤ì¹­
                    common_info = common_columns.get(column_name, {})

                    writer.writerow([
                        table_name,
                        column_name,
                        common_info.get('korean_name', ''),  # ê³µí†µ ì •ë³´ ì‚¬ìš©
                        common_info.get('description', ''),  # ê³µí†µ ì •ë³´ ì‚¬ìš©
                        common_info.get('business_rule', ''),
                        common_info.get('sample_values', ''),
                        common_info.get('unit', ''),
                        'Y' if common_info.get('is_code_column', False) else 'N',
                        common_info.get('aggregation_functions', ''),
                        'Y' if common_info.get('is_sensitive', False) else 'N'
                    ])

    def _generate_code_values_csv(
        self,
        tables_columns: Dict[str, List[Dict]],
        code_definitions: Dict[str, Dict[str, Dict]],
        output_path: Path
    ):
        """code_values.csv ìƒì„± (ì½”ë“œ ì •ë³´ ë§¤í•‘)"""
        with open(output_path, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.writer(f)

            # í—¤ë”
            writer.writerow([
                'table_name',
                'column_name',
                'code_value',
                'code_label',
                'code_description',
                'display_order',
                'is_active',
                'parent_code',
                'state_transition'
            ])

            # ì½”ë“œ ì¹¼ëŸ¼ ì°¾ê¸°
            written_columns = set()

            for table_name in sorted(tables_columns.keys()):
                columns = tables_columns[table_name]

                for col in columns:
                    column_name = col['name']

                    # ì´ë¯¸ ì‘ì„±ëœ ì¹¼ëŸ¼ì€ ìŠ¤í‚µ (ì¤‘ë³µ ë°©ì§€)
                    if column_name in written_columns:
                        continue

                    # ì½”ë“œ ì •ì˜ê°€ ìˆëŠ” ì¹¼ëŸ¼ë§Œ
                    if column_name in code_definitions:
                        codes = code_definitions[column_name]

                        for code_value, code_info in codes.items():
                            writer.writerow([
                                table_name,
                                column_name,
                                code_value,
                                code_info.get('code_label', ''),
                                code_info.get('code_description', ''),
                                code_info.get('display_order', ''),
                                'Y' if code_info.get('is_active', True) else 'N',
                                code_info.get('parent_code', ''),
                                code_info.get('state_transition', '')
                            ])

                        written_columns.add(column_name)

    # ============================================
    # ìœ í‹¸ë¦¬í‹°
    # ============================================

    def get_statistics(self, database_sid: str) -> Dict:
        """ì €ì¥ëœ ë©”íƒ€ë°ì´í„° í†µê³„"""
        common_columns = self.load_common_columns(database_sid)
        code_definitions = self.load_code_definitions(database_sid)

        # ì½”ë“œ ì¹¼ëŸ¼ ìˆ˜
        code_column_count = len(code_definitions)

        # ì „ì²´ ì½”ë“œ ìˆ˜
        total_codes = sum(len(codes) for codes in code_definitions.values())

        return {
            'database_sid': database_sid,
            'common_column_count': len(common_columns),
            'code_column_count': code_column_count,
            'total_code_count': total_codes
        }


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    manager = CommonMetadataManager()

    # ê³µí†µ ì¹¼ëŸ¼ ì •ë³´ ì €ì¥
    columns = [
        {
            'column_name': 'STATUS',
            'korean_name': 'ìƒíƒœ',
            'description': 'ì²˜ë¦¬ ìƒíƒœ ì½”ë“œ',
            'is_code_column': True,
            'sample_values': '01|02|03',
            'business_rule': '01â†’02â†’03 ìˆœì„œ',
            'unit': '',
            'aggregation_functions': '',
            'is_sensitive': False
        }
    ]

    manager.save_common_columns(columns)
    print("âœ… ê³µí†µ ì¹¼ëŸ¼ ì •ë³´ ì €ì¥ ì™„ë£Œ")

    # ì½”ë“œ ì •ë³´ ì €ì¥
    codes = [
        {
            'column_name': 'STATUS',
            'code_value': '01',
            'code_label': 'ì ‘ìˆ˜',
            'code_description': 'ì ‘ìˆ˜ëœ ìƒíƒœ',
            'display_order': 1,
            'is_active': True,
            'parent_code': '',
            'state_transition': '02'
        }
    ]

    manager.save_code_definitions(codes)
    print("âœ… ì½”ë“œ ì •ë³´ ì €ì¥ ì™„ë£Œ")

    # í†µê³„
    stats = manager.get_statistics()
    print(f"ğŸ“Š í†µê³„: {stats}")
