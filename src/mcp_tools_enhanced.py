"""
Enhanced MCP Tools for Backend Integration
New tools that leverage the FastAPI backend with Vector DB and Learning Engine
"""

import logging
from typing import List, Dict, Any
from backend_client import get_backend_client

logger = logging.getLogger(__name__)


async def get_table_summaries_for_query_v2(
    database_sid: str,
    schema_name: str,
    natural_query: str = ""
) -> List[Dict]:
    """
    ìì—°ì–´ ì¿¼ë¦¬ë¥¼ ìœ„í•œ í…Œì´ë¸” ìš”ì•½ ì •ë³´ ì œê³µ (Stage 1 - Vector DB ë²„ì „)

    ì´ ë²„ì „ì€ Backendì˜ Vector DBë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    ê¸°ì¡´ JSON íŒŒì¼ ê¸°ë°˜ë³´ë‹¤ í›¨ì”¬ ë¹ ë¦…ë‹ˆë‹¤ (5-10ì´ˆ â†’ 1ì´ˆ ë¯¸ë§Œ).
    """
    try:
        # Try backend first
        backend = get_backend_client()
        health = await backend.check_health()

        if health.get("api") == "healthy" and health.get("vector_db") == "healthy":
            logger.info("Using Vector DB backend for metadata search")

            # Search using Vector DB
            result = await backend.search_metadata(
                question=natural_query,
                database_sid=database_sid,
                schema_name=schema_name,
                limit=10  # Get top 10 most relevant tables
            )

            if result.get("total_found", 0) > 0:
                result_text = f"ğŸ“Š í…Œì´ë¸” ìš”ì•½ ì •ë³´ (Stage 1 - Vector DB)\n\n"
                result_text += f"**ì§ˆë¬¸**: {natural_query}\n\n"
                result_text += f"**Database**: {database_sid}\n"
                result_text += f"**Schema**: {schema_name}\n"
                result_text += f"**ê²€ìƒ‰ ë°©ì‹**: ğŸš€ Vector DB ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ (ì´ˆê³ ì†)\n"
                result_text += f"**ê´€ë ¨ í…Œì´ë¸” ìˆ˜**: {result['total_found']}ê°œ\n\n"
                result_text += "**í…Œì´ë¸” ëª©ë¡ (ê´€ë ¨ë„ ìˆœ)**:\n\n"

                for i, table_result in enumerate(result.get("results", []), 1):
                    similarity_pct = table_result["similarity_score"] * 100
                    result_text += f"### {i}. {table_result['table_name']} "
                    result_text += f"(ìœ ì‚¬ë„: {similarity_pct:.1f}%)\n"

                    if table_result.get("korean_name"):
                        result_text += f"- **í•œê¸€ëª…**: {table_result['korean_name']}\n"

                    if table_result.get("description"):
                        result_text += f"- **ì„¤ëª…**: {table_result['description']}\n"

                    result_text += f"- **ì»¬ëŸ¼ ìˆ˜**: {table_result.get('column_count', 'N/A')}\n\n"

                result_text += "\n---\n\n"
                result_text += "**ë‹¤ìŒ ë‹¨ê³„**: ìœ„ í…Œì´ë¸”ë“¤ ì¤‘ì—ì„œ ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ í•„ìš”í•œ í…Œì´ë¸”(ìµœëŒ€ 5ê°œ)ì„ ì„ íƒí•˜ê³ ,\n"
                result_text += "`get_detailed_metadata_for_sql` Toolì„ í˜¸ì¶œí•˜ì—¬ ìƒì„¸ ë©”íƒ€ë°ì´í„°ë¥¼ ë°›ì•„ SQLì„ ìƒì„±í•˜ì„¸ìš”.\n\n"
                result_text += "ğŸ’¡ **TIP**: Vector DBëŠ” ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ í…Œì´ë¸”ì„ ìë™ìœ¼ë¡œ ì°¾ì•„ì¤ë‹ˆë‹¤. "
                result_text += "ìœ ì‚¬ë„ê°€ ë†’ì€ ìƒìœ„ í…Œì´ë¸”ë“¤ì„ ìš°ì„  ì„ íƒí•˜ì„¸ìš”."

                return [{"type": "text", "text": result_text}]

        # Fallback to original JSON-based method
        logger.warning("Backend unavailable, falling back to JSON files")
        from metadata_manager import MetadataManager
        from common_metadata_manager import CommonMetadataManager

        common_metadata_manager = CommonMetadataManager()
        metadata_manager = MetadataManager(common_metadata_manager=common_metadata_manager)

        summaries_data = metadata_manager.load_table_summaries(database_sid, schema_name)

        result_text = f"ğŸ“Š í…Œì´ë¸” ìš”ì•½ ì •ë³´ (Stage 1 - Fallback)\n\n"
        result_text += f"âš ï¸ Backendê°€ ì‚¬ìš© ë¶ˆê°€í•˜ì—¬ JSON íŒŒì¼ ëª¨ë“œë¡œ ë™ì‘ ì¤‘ì…ë‹ˆë‹¤.\n\n"
        result_text += f"**ì§ˆë¬¸**: {natural_query}\n\n"
        result_text += f"**Database**: {database_sid}\n"
        result_text += f"**Schema**: {schema_name}\n"
        result_text += f"**ì „ì²´ í…Œì´ë¸” ìˆ˜**: {summaries_data.get('total_tables', 0)}ê°œ\n\n"
        result_text += "**í…Œì´ë¸” ëª©ë¡**:\n\n"

        for summary in summaries_data.get('summaries', []):
            result_text += f"### {summary.get('table_name')}\n"
            result_text += f"- **ì„¤ëª…**: {summary.get('one_line_desc', 'N/A')}\n"
            result_text += f"- **ì£¼ìš” ìš©ë„**: {summary.get('primary_use', 'N/A')}\n"
            result_text += f"- **í‚¤ì›Œë“œ**: {', '.join(summary.get('keywords', []))}\n\n"

        result_text += "\n---\n\n"
        result_text += "**ë‹¤ìŒ ë‹¨ê³„**: ìœ„ í…Œì´ë¸”ë“¤ ì¤‘ì—ì„œ ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ í•„ìš”í•œ í…Œì´ë¸”(ìµœëŒ€ 5ê°œ)ì„ ì„ íƒí•˜ê³ ,\n"
        result_text += "`get_detailed_metadata_for_sql` Toolì„ í˜¸ì¶œí•˜ì—¬ ìƒì„¸ ë©”íƒ€ë°ì´í„°ë¥¼ ë°›ì•„ SQLì„ ìƒì„±í•˜ì„¸ìš”.\n"

        return [{"type": "text", "text": result_text}]

    except FileNotFoundError:
        return [{
            "type": "text",
            "text": f"âŒ í…Œì´ë¸” ìš”ì•½ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤: {database_sid}.{schema_name}\në©”íƒ€ë°ì´í„°ë¥¼ ë¨¼ì € ì¶”ì¶œí•´ì£¼ì„¸ìš”."
        }]
    except Exception as e:
        import traceback
        logger.error(f"í…Œì´ë¸” ìš”ì•½ ì¡°íšŒ ì‹¤íŒ¨: {e}\n{traceback.format_exc()}")
        return [{
            "type": "text",
            "text": f"âŒ í…Œì´ë¸” ìš”ì•½ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}\n\n{traceback.format_exc()}"
        }]


async def find_similar_sql_pattern(
    database_sid: str,
    schema_name: str,
    natural_query: str,
    similarity_threshold: float = 0.85
) -> List[Dict]:
    """
    ìœ ì‚¬í•œ SQL íŒ¨í„´ ì°¾ê¸° (Learning Engine)

    ì´ì „ì— ì„±ê³µì ìœ¼ë¡œ ìƒì„±ëœ SQL ì¤‘ì—ì„œ í˜„ì¬ ì§ˆë¬¸ê³¼ ìœ ì‚¬í•œ íŒ¨í„´ì„ ì°¾ìŠµë‹ˆë‹¤.
    íŒ¨í„´ì´ ë°œê²¬ë˜ë©´ SQLì„ ìƒˆë¡œ ìƒì„±í•˜ì§€ ì•Šê³  ì¬ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """
    try:
        backend = get_backend_client()

        # Check if backend is available
        health = await backend.check_health()
        if health.get("api") != "healthy":
            return [{
                "type": "text",
                "text": "âš ï¸ Learning Engineì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Backendê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”."
            }]

        # Find similar pattern
        result = await backend.find_similar_pattern(
            question=natural_query,
            database_sid=database_sid,
            schema_name=schema_name,
            similarity_threshold=similarity_threshold
        )

        if result.get("found_match"):
            pattern = result["pattern"]
            similarity_pct = pattern["similarity"] * 100
            success_rate_pct = pattern["success_rate"] * 100

            result_text = f"âœ… ìœ ì‚¬í•œ SQL íŒ¨í„´ ë°œê²¬!\n\n"
            result_text += f"**ì§ˆë¬¸**: {natural_query}\n\n"
            result_text += f"**ë§¤ì¹­ëœ ì´ì „ ì§ˆë¬¸**: {pattern['question']}\n\n"
            result_text += f"**ìœ ì‚¬ë„**: {similarity_pct:.1f}%\n"
            result_text += f"**ì„±ê³µë¥ **: {success_rate_pct:.1f}% (ì‚¬ìš© {pattern['use_count']}íšŒ)\n"
            result_text += f"**ì „ì²´ ì ìˆ˜**: {pattern['overall_score']:.2f}\n\n"
            result_text += "**ì¬ì‚¬ìš© ê°€ëŠ¥í•œ SQL**:\n\n"
            result_text += "```sql\n"
            result_text += pattern["sql_query"]
            result_text += "\n```\n\n"
            result_text += "---\n\n"
            result_text += "ğŸ’¡ **ì¶”ì²œ**: ì´ SQLì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ê±°ë‚˜ ì•½ê°„ ìˆ˜ì •í•˜ì—¬ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
            result_text += "ì´ë ‡ê²Œ í•˜ë©´ LLM API ë¹„ìš©ì„ ì ˆì•½í•˜ê³  ì‘ë‹µ ì†ë„ë¥¼ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n"
            result_text += f"**Pattern ID**: `{pattern['pattern_id']}`\n"
            result_text += "(í”¼ë“œë°±ì„ ì£¼ê³  ì‹¶ìœ¼ë©´ ì´ IDë¥¼ ì‚¬ìš©í•˜ì„¸ìš”)"

            return [{"type": "text", "text": result_text}]
        else:
            result_text = f"â„¹ï¸ ìœ ì‚¬í•œ SQL íŒ¨í„´ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\n\n"
            result_text += f"**ì§ˆë¬¸**: {natural_query}\n\n"
            result_text += "ìƒˆë¡œìš´ SQLì„ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤. ìƒì„± í›„ì—ëŠ” `learn_sql_pattern` Toolì„ ì‚¬ìš©í•˜ì—¬\n"
            result_text += "ì´ íŒ¨í„´ì„ ì €ì¥í•˜ë©´ ë‹¤ìŒì— ìœ ì‚¬í•œ ì§ˆë¬¸ì— ì¬ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."

            return [{"type": "text", "text": result_text}]

    except Exception as e:
        import traceback
        logger.error(f"íŒ¨í„´ ì°¾ê¸° ì‹¤íŒ¨: {e}\n{traceback.format_exc()}")
        return [{
            "type": "text",
            "text": f"âŒ íŒ¨í„´ ì°¾ê¸° ì‹¤íŒ¨: {str(e)}\n\n{traceback.format_exc()}"
        }]


async def learn_sql_pattern(
    database_sid: str,
    schema_name: str,
    natural_query: str,
    sql_query: str,
    tables_used: str,  # Comma-separated table names
    execution_success: bool = True,
    execution_time_ms: float = None,
    row_count: int = None
) -> List[Dict]:
    """
    SQL íŒ¨í„´ í•™ìŠµ (Learning Engine)

    ì„±ê³µì ìœ¼ë¡œ ìƒì„±/ì‹¤í–‰ëœ SQLì„ ì €ì¥í•˜ì—¬ ë‚˜ì¤‘ì— ìœ ì‚¬í•œ ì§ˆë¬¸ì— ì¬ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """
    try:
        backend = get_backend_client()

        # Check backend availability
        health = await backend.check_health()
        if health.get("api") != "healthy":
            return [{
                "type": "text",
                "text": "âš ï¸ Learning Engineì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Backendê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”."
            }]

        # Parse tables
        tables_list = [t.strip() for t in tables_used.split(',')]

        # Learn pattern
        pattern_id = await backend.learn_sql_pattern(
            question=natural_query,
            sql_query=sql_query,
            database_sid=database_sid,
            schema_name=schema_name,
            tables_used=tables_list,
            execution_success=execution_success,
            execution_time_ms=execution_time_ms,
            row_count=row_count
        )

        result_text = f"âœ… SQL íŒ¨í„´ì´ í•™ìŠµë˜ì—ˆìŠµë‹ˆë‹¤!\n\n"
        result_text += f"**ì§ˆë¬¸**: {natural_query}\n\n"
        result_text += f"**ì‚¬ìš©ëœ í…Œì´ë¸”**: {', '.join(tables_list)}\n"
        result_text += f"**ì‹¤í–‰ ì„±ê³µ**: {'âœ… ì˜ˆ' if execution_success else 'âŒ ì•„ë‹ˆì˜¤'}\n"

        if execution_time_ms is not None:
            result_text += f"**ì‹¤í–‰ ì‹œê°„**: {execution_time_ms:.2f}ms\n"

        if row_count is not None:
            result_text += f"**ê²°ê³¼ í–‰ ìˆ˜**: {row_count}ê°œ\n"

        result_text += f"\n**Pattern ID**: `{pattern_id}`\n\n"
        result_text += "---\n\n"
        result_text += "ğŸ’¡ ì´ íŒ¨í„´ì€ ì´ì œ Vector DBì— ì €ì¥ë˜ì–´, ë‹¤ìŒì— ìœ ì‚¬í•œ ì§ˆë¬¸ì´ ì˜¤ë©´\n"
        result_text += "ìë™ìœ¼ë¡œ ì¬ì‚¬ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ LLM API ë¹„ìš©ì„ 60% ì ˆê°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!"

        return [{"type": "text", "text": result_text}]

    except Exception as e:
        import traceback
        logger.error(f"íŒ¨í„´ í•™ìŠµ ì‹¤íŒ¨: {e}\n{traceback.format_exc()}")
        return [{
            "type": "text",
            "text": f"âŒ íŒ¨í„´ í•™ìŠµ ì‹¤íŒ¨: {str(e)}\n\n{traceback.format_exc()}"
        }]


async def get_learning_stats(database_sid: str = None, schema_name: str = None) -> List[Dict]:
    """
    Learning Engine í†µê³„ ì¡°íšŒ

    í•™ìŠµëœ SQL íŒ¨í„´ì˜ í†µê³„ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
    """
    try:
        backend = get_backend_client()

        # Check backend availability
        health = await backend.check_health()
        if health.get("api") != "healthy":
            return [{
                "type": "text",
                "text": "âš ï¸ Learning Engineì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Backendê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”."
            }]

        # Get stats
        stats = await backend.get_pattern_stats()

        result_text = f"ğŸ“Š Learning Engine í†µê³„\n\n"
        result_text += f"**í•™ìŠµëœ íŒ¨í„´ ìˆ˜**: {stats['total_patterns']}ê°œ\n"
        result_text += f"**í‰ê·  ì„±ê³µë¥ **: {stats['avg_success_rate'] * 100:.1f}%\n"
        result_text += f"**ì´ ì¬ì‚¬ìš© íšŸìˆ˜**: {stats['total_reuses']}íšŒ\n"
        result_text += f"**ì ˆê°ëœ LLM í˜¸ì¶œ**: {stats['estimated_llm_calls_saved']}íšŒ\n\n"

        if stats['estimated_llm_calls_saved'] > 0:
            estimated_cost_saved = stats['estimated_llm_calls_saved'] * 0.01  # Assume $0.01 per call
            result_text += f"**ì˜ˆìƒ ì ˆê° ë¹„ìš©**: ${estimated_cost_saved:.2f}\n\n"

        result_text += "---\n\n"

        if stats['total_patterns'] == 0:
            result_text += "ì•„ì§ í•™ìŠµëœ íŒ¨í„´ì´ ì—†ìŠµë‹ˆë‹¤. SQLì„ ìƒì„±/ì‹¤í–‰í•œ í›„\n"
            result_text += "`learn_sql_pattern` Toolì„ ì‚¬ìš©í•˜ì—¬ íŒ¨í„´ì„ ì €ì¥í•˜ì„¸ìš”."
        else:
            result_text += "ğŸ’¡ **ì„±ê³¼**: í•™ìŠµëœ íŒ¨í„´ë“¤ì´ ìë™ìœ¼ë¡œ ì¬ì‚¬ìš©ë˜ì–´ LLM API ë¹„ìš©ì„ ì ˆê°í•˜ê³  ìˆìŠµë‹ˆë‹¤!"

        return [{"type": "text", "text": result_text}]

    except Exception as e:
        import traceback
        logger.error(f"í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}\n{traceback.format_exc()}")
        return [{
            "type": "text",
            "text": f"âŒ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}\n\n{traceback.format_exc()}"
        }]


async def migrate_metadata_to_vectordb(
    database_sid: str,
    schema_name: str,
    metadata_dir: str = None
) -> List[Dict]:
    """
    JSON ë©”íƒ€ë°ì´í„°ë¥¼ Vector DBë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜

    ê¸°ì¡´ JSON íŒŒì¼ ê¸°ë°˜ ë©”íƒ€ë°ì´í„°ë¥¼ Vector DBë¡œ í•œë²ˆì— ì´ë™í•©ë‹ˆë‹¤.
    ì´ ì‘ì—…ì€ ë°ì´í„°ë² ì´ìŠ¤ë‹¹ í•œ ë²ˆë§Œ ìˆ˜í–‰í•˜ë©´ ë©ë‹ˆë‹¤.
    """
    try:
        backend = get_backend_client()

        # Check backend availability
        health = await backend.check_health()
        if health.get("api") != "healthy":
            return [{
                "type": "text",
                "text": "âš ï¸ Backendë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Backendê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”."
            }]

        # Default metadata directory
        if metadata_dir is None:
            from pathlib import Path
            metadata_dir = str(Path(__file__).parent.parent / "metadata")

        # Migrate
        result = await backend.migrate_metadata(
            metadata_dir=metadata_dir,
            database_sid=database_sid,
            schema_name=schema_name
        )

        if result.get("success"):
            tables_migrated = result["tables_migrated"]

            result_text = f"âœ… ë©”íƒ€ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!\n\n"
            result_text += f"**Database**: {database_sid}\n"
            result_text += f"**Schema**: {schema_name}\n"
            result_text += f"**ë§ˆì´ê·¸ë ˆì´ì…˜ëœ í…Œì´ë¸”**: {tables_migrated}ê°œ\n\n"
            result_text += "---\n\n"
            result_text += "ğŸš€ ì´ì œ Vector DBë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ˆê³ ì† ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤!\n\n"
            result_text += "**ë‹¤ìŒ ë‹¨ê³„**:\n"
            result_text += "- `get_table_summaries_for_query_v2` Toolì„ ì‚¬ìš©í•˜ì—¬ Vector DB ê²€ìƒ‰ ì²´í—˜\n"
            result_text += "- ê¸°ì¡´ `get_table_summaries_for_query` ëŒ€ì‹  v2 ë²„ì „ ì‚¬ìš© ê¶Œì¥"

            return [{"type": "text", "text": result_text}]
        else:
            error_msg = result.get("error", "Unknown error")
            result_text = f"âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨\n\n"
            result_text += f"**ì—ëŸ¬**: {error_msg}\n\n"
            result_text += "**ê°€ëŠ¥í•œ ì›ì¸**:\n"
            result_text += "- JSON ë©”íƒ€ë°ì´í„° íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ\n"
            result_text += "- Backendê°€ ì œëŒ€ë¡œ ì‹¤í–‰ë˜ì§€ ì•ŠìŒ\n"
            result_text += "- ë””ë ‰í† ë¦¬ ê²½ë¡œê°€ ì˜ëª»ë¨"

            return [{"type": "text", "text": result_text}]

    except Exception as e:
        import traceback
        logger.error(f"ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}\n{traceback.format_exc()}")
        return [{
            "type": "text",
            "text": f"âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {str(e)}\n\n{traceback.format_exc()}"
        }]
